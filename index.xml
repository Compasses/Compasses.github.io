<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>三十重围</title>
    <link>http://www.heguangnan.com/</link>
    <description>Recent content on 三十重围</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-EN</language>
    <lastBuildDate>Tue, 25 Jul 2017 14:59:49 +0800</lastBuildDate>
    
	<atom:link href="http://www.heguangnan.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>加密算法</title>
      <link>http://www.heguangnan.com/post/understanding_ecc/</link>
      <pubDate>Tue, 25 Jul 2017 14:59:49 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/understanding_ecc/</guid>
      <description>密码学技术是区块链技术的基石，不管是比特币还是以太坊，交易的完成离不开密码学技术的应用。例如用户签名，P2P网络数据的传输等，整个系统的运转其实是个混合密码系统。 在理解区块链技术的过程中，避免不了密码学的认识，其中椭圆曲线密码使用的更为广泛，由于其效率高、强度大被比特币和以太坊大量使用。如果之前没有做过密码学相关的工作， 直接做区块链相关的技术回比较吃力。密码学相关的技术还是好好理解下，在理解认识椭圆曲线密码之前，先认识下RSA和DH密码交换。
RSA RSA也称为非对称密码，椭圆曲线只不过是非对称密码的另一种实现和应用。 RSA计算过程： 从图中可以看出，一切从p和q出发，两个比较大的质数，求出E，D，N的过程。其中（E，N）组合成公钥，（D，N）组合成私钥。其中：
L = lcm(p-1, q-1) 最小公倍数 gcd(E, L) = 1 最大公约数为1 1&amp;lt;E&amp;lt;L 1&amp;lt;D&amp;lt;L 加密过程：密文 = 明文^E mod N 解密过程：明文 = 密文^D mod N  算法看起来非常大简洁和清晰，但是背后的原理就复杂的多了，需要用到很多数论、代数的知识。 RSA在使用过程中大多数的场景都是用来进行密钥交换，因为安全性好，不存在共享密钥问题，但是效率上不如对称密钥，所以很多情况下都是混合使用对称和非对称加密。 同样的使用RSA也可以进行数字签名：
签名 = 消息^D mod N 签名消息 = 签名^E mod N  可以看出数字签名和加密解密过程正好相反。 综上，RSA是利用了大数质数分解难题。
密钥交换/协商 共享密钥就会有密钥配送问题，Diffie-Hellman是解决这一问题的重要算法。 其计算流程：
对于可公开的数，G和P，P是一个非常大的质数，而G则是P的一个生成元。DH跟椭圆曲线加密算法一样，都是建立在离散对数问题上。 根据G^A mod P计算出A，就是所谓的有限域上的离散对数问题。目前还没有有效的算法来解决这个问题。 生成元的概念在近世代数中可以找到，是群论中的基础。G是P的生成元满足，G的乘方结果与1到p-1的数字一一对应。例如2是13的生成元，满足2的一次方到2的十二次方的结果 跟13取余，正好在1到12相对应。 与RSA不同，Diffie-Hellman是利用了离散对数问题，即以一个大质数P为模，已知G和G^x mod P，求x，同样的没有有效算法。
椭圆曲线密码学 椭圆曲线密码学:Elliptic Curve Cryptography，是利用椭圆曲线来实现的密码技术，与RSA相比，密钥可以更短，但强度更高。现在已广泛使用。 特别blockchain技术中，加密是重要的一环，比特币中便是使用了椭圆曲线密码技术，以太坊中也是使用的椭圆曲线DSA， 更为一般的HTTPS中使用的TLS也是基于椭圆曲线实现的密码交换。
椭圆曲线密码技术包含三个方面：
 基于椭圆曲线的公钥密码 基于椭圆曲线的数字签名 基于椭圆曲线的密钥交换  下面会对这些技术进行一一梳理，现在先看下椭圆曲线的定义：</description>
    </item>
    
    <item>
      <title>ElasticSearch：Search &amp; Query DSL的生成</title>
      <link>http://www.heguangnan.com/post/elastic_dsl/</link>
      <pubDate>Wed, 14 Jun 2017 16:32:36 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/elastic_dsl/</guid>
      <description>这是ES相关的第四篇日志，另外三篇由于是一起写完的，所以放在一起了：ElasticSearch使用。 看到现在已经是5个月后，其实各种研究、验证和原型早就开发完了，由于项目需求的原因，用ES实现的电商平台垂直搜索功能直到最近才release。 相关的代码也在这个project里面，具体内容请移步：
ElasticSearch 深入理解 四：Search &amp;amp; Query DSL的生成
项目使用过程中，ES的官方文档基本上捋了一遍，还是比较详尽的，你所想了解的东西都基本上都能得到满足。不得不说一个开源项目的成功不是随随便便的，有很多深厚的积累。另外针对ES的使用如果项目有深层次的需求，基于ES做二次开发，也是非常方便的，它的plugin机制也提供了另外一条各种定制之路。
以上是自己对ES的理解和总结，至于是『深入理解』也是对自己而言。</description>
    </item>
    
    <item>
      <title>ES memory leak</title>
      <link>http://www.heguangnan.com/post/es_memleak/</link>
      <pubDate>Thu, 25 May 2017 14:59:49 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/es_memleak/</guid>
      <description>从这篇文章中得知ES在5.1版本中有原生内存泄露的问题， 而碰巧我们生产环境中也在使用5.1系列的版本，但是场景不一样。比如我们并没有使用x-pack，但是还是放心不下，决定在我们的场景下利用文章中的方法进行下测试。
先弄清楚要测试的问题，Java的内存问题，大多数集中在Java Heap上面，所以平时遇到native memory的问题几率较低。Heap是Java新对象创建的地方也是GC工作的 主要区域，平时如果遇到Heap内存问题，通过收集GC日志，基本上就能看出端倪。例如GC时间过长、GC过于频繁的话需要进行GC算法参数的调优，老年代持续增长的话就要看对象是否分配的合理了，这也是一种泄露-导致GC无法回收。不同的GC算法调优的参数不一样，但目前还是用的CMS，有时间可以总结下。
另外就是native memory的问题，例如出现了Outofmemory的错误：
Allocated 1953546736 bytes of native memory before running out Exception in thread &amp;quot;main&amp;quot; java.lang.OutOfMemoryError: unable to create new native thread at java.lang.Thread.start0(Native Method) at java.lang.Thread.start(Thread.java:574) at com.ibm.jtc.demos.StartingAThreadUnderNativeStarvation.main( StartingAThreadUnderNativeStarvation.java:22)  遇到这样的问题，首先要确定的是是不是由堆内存申请导致的，如果不是就有可能是下面两种： 1. MetaSpace 2. Native memory
只要是JVM相关的内存问题，通过相关的监控工具都能很好的判定，例如如果集成了Metrics，可以得到
通过这样的监控可以很容易的可以看出内存问题是否是出自于JVM。
扯得有点远了，回归主题：native memory tracking。 需要清楚的是Native memory tracking是tracking Java进程申请的OS内存，即glibc申请内存的情况。而 jemalloc这个工具可以帮助我们抓取到Java进程的内存申请行为。过程也颇为简单：
git clone https://github.com/jemalloc/jemalloc git checkout stable-4 ./autogen.sh ./configure --enable-perf make sudo make install  启动ES之前设置下环境变量：
export LD_PRELOAD=/usr/local/lib/libjemalloc.so export MALLOC_CONF=prof:true,lg_prof_interval:30,lg_prof_sample:17,prof_final:true  环境变量LD_PRELOAD用来替换原生的glibc malloc。 然后启动ES，运行一段时间，停掉后会生成多个jeprof.</description>
    </item>
    
    <item>
      <title>读书：Functional Programming In Scala （Part 1）</title>
      <link>http://www.heguangnan.com/post/functionalprogramming/</link>
      <pubDate>Wed, 05 Apr 2017 17:36:47 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/functionalprogramming/</guid>
      <description>学习Scala更多的是一种思想的转变。不同于传统的编程语言，例如C++，Java，Golang等，个人感觉他们没有本质的区别，无非是内存、CPU、IO等等，或者他们都是命令式的编程思想，面向冯诺依曼体系结构的。无非就是内存、变量、赋值、表达式、控制结构等。所以这些语言，使用起来没有太多违和感，特别是有了较多的C++开发经验的时候。
Scala不同，它不再是那种冯诺依曼体系结构的编程思想了，更多的是一种数学的编程思想的体现。通过这本书：Functional Programming in Scala，可以很好的了解到这种思想的转变。所以要比较好的掌握Scala，思想转变是必须的。那么好好看看这本书也是理所当然的了。
Functional Programming是个很大的topic，它的理论基础是Lambda calculus，Lambda calculus是一种数学计算抽象。跟上面所说那样，Lambda calculus不会关注内存、变量、赋值等语句了，而更多的是各种函数算子的变换。研究生还上过这个计算理论课，可惜当时没有学习一门函数式编程语言。所以函数式编程可以理解为面向函数的编程。就像Java一样，面向对象的编程。函数式编程的理论基础便是Lambda calculus，这里有对其比较清晰的介绍。
举几个例子:
例如数学里面的函数二元变量的函数：f(x, y) = x*x + y*y，可以抽象表示成：x-&amp;gt;(y-&amp;gt;x*x+y*y)，那么一次调用(x-&amp;gt;(y-&amp;gt;x*x+y*y))(3)(4)，就如同调用f(3, 4)。所以可以把任意的多元函数转变成一元的高阶函数，这个过程也要Currying。例如代码：
def foldLeft[A,B](as: List[A], z: B)(f: (B, A) =&amp;gt; B): B = as match { case Nil =&amp;gt; z case Cons(h, t) =&amp;gt; foldLeft(t, f(z,h))(f) }  其中List的定义：
sealed trait List[+A] case object Nil extends List[Nothing] case class Cons[+A](head: A, tail: List[A]) extends List[A]  理解foldLeft是理解其他函数的基础。它所做的就是将链表中的元素实施一个函数变换，也可以理解为规约。比如一个例子：
def sum(ns: List[Int]) = foldLeft(ns, 0)((x,y)=&amp;gt;x+y)  很明显这个函数就是求取这个list的sum。通过一个函数的组合调用就能完成。如果换成其他语言来完成这个运算，可能想到的就是通过循环，定义sum变量，进行累加了。</description>
    </item>
    
    <item>
      <title>Kibana and Grafana</title>
      <link>http://www.heguangnan.com/post/elasticsearch-kibana-grafana/</link>
      <pubDate>Thu, 16 Mar 2017 14:59:49 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/elasticsearch-kibana-grafana/</guid>
      <description>如果能把数据的实时的可视化，应该是个很好的应用方向。比如目前用的比较多的ELK，做日志分析，做系统监控。中间使用Logstash或者Beats把数据收集到ElasticSearch里面，通过Kibana做查询，然后通过配置DashBoard把展示出来。
最近在用Kibana做一些数据的查询优化，发现他的可视化功能还是不错的，但是跟Grafana相比，功能上还是欠缺了些。可视化数据的需求，是方方面面的。大公司的报表，企业做BI、信息化，都离不开数据分析。如果数据能够通过各种维度展现出来，让人更好的理解数据，才能更好的利用数据。所以可视化将会是大数据分析的必然需求。
在研究怎么样更好的去检索ES时，利用了Kibana的Dev Tools并进一步了解到了他的visualize功能。因为之前也使用过Grafana，发现它也支持ES，发现其在可视化ES的数据时更加方便和自由。
ES数据类型 数据分析跟全文检索不一样，如果字段类型是text的，ES会做分词处理，这种主要用于全文检索。数据分析时，检索的时候可能会看到不想要的结果，所以如果单纯的做可视化，最好将Mapping修改下，将字段类型改为keyword。这个目前只在用Grafana的时候有些问题，Kibana倒是问题不大。
Kibana Kibana安装非常方便，官网下载，并配置下ES的URL就可以连上了。Kibana使用的时候会有副作用，它会在你的ES里面创建一个它所需要的Index，并会有较为频繁的query。如果是生产环境，ES存的是核心数据要慎用了。安装好启动指定需要分析的Index，就能看到以下几个Tab。
 Discover，查询时用的比较多，查询日志信息的时候。可以进行任意的查询，能快速的定位问题。 Visualize，提供很多种类型的图展示方式。 Dev Tools，提供了很好的跟ES交互的工具，比Postman更方便，感觉可以不用Postman了。 Dashboard，Visuallize里面定义的视图可以保存到Dashboard上面，这样可以看到实时分析的结果。  Kibana总体上来讲使用比较傻瓜式的，基本上用鼠标选择下就能用。Dev Tools是个很好的工具HTTP请求写起来很方便，也有历史记录。ES的Search都是Get带body的，在Dev Tools里面很方便使用。
例如：
GET _search { &amp;quot;query&amp;quot;: { &amp;quot;match_all&amp;quot;: {} } }  鼠标点上GET那一行就能发出去了。手写JSON也毫不费力。
Grafana 印象中Grafana是InfluxDB可视化工具，但基于Grafana良好的架构，DataSource可以变得多样性了，现在是支持ElasticSearch作为DataSource的。 Grafana的安装也非常简单，解压启动就可以了。DataSource都是动态添加上去的。Grafana作为一个纯粹的可视化工具，灵活性做到了极致。使用ElasticSearch作为DataSource，指定对应的Index，就可以建立DashBoard就行数据可视化了。相比Kibana，Grafana的template功能能把数据按照任意的维度进行切分展示，这就是它的强大之处。
Grafana需要index有个时间序列的字段，这个其实不难，正常的数据都会有个时间字段的。下面举个例子，有一批专利申请的数据，通过某种手段导入到ES中。例如以专利申请的国家和类型进行切分的话，那就要建立两个模板： 国家的模板，query中填写：
{&amp;quot;find&amp;quot;: &amp;quot;terms&amp;quot;, &amp;quot;field&amp;quot;: &amp;quot;国家&amp;quot;}  专利类型的模板，query中填写：
{&amp;quot;find&amp;quot;: &amp;quot;terms&amp;quot;, &amp;quot;field&amp;quot;: &amp;quot;专利类型&amp;quot;}  然后添加panel类型为Graph，以“发明人”字段作为聚合数据。edit panel中的query填写：
国家:$country AND 专利类型:$type  graph左上角就会有两个选择列表：
例如发明人的panel展示：
可以随意选择维度就行分析。
Grafana还有较为完善的用户管理，这也是强于Kibana的地方。
Summary 不管是Kibana还是Grafana，都会容易联想到系统监控，日志分析。没错这是它们的强项，不管事序列化的数据还是Metrics Data都能很好的展示出来，让对应的DevOps做监控预警等。从另一方面讲，其他的任何数据，能把数据保存到ES，配合Grafana或者Kibana都能很好的做分析展示。当然更看好Grafana，随着Grafana的功能进一步增强，会变得功能更加强大，图表也会更加多样性。下一步结合Spark或者Hadoop，做个实时的BI也是个不错的方向哦。</description>
    </item>
    
    <item>
      <title>回顾下过去，坚定下未来</title>
      <link>http://www.heguangnan.com/post/retrospect/</link>
      <pubDate>Sat, 11 Mar 2017 17:08:03 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/retrospect/</guid>
      <description>从2011年毕业至今，差不多工作六年了。想回顾下过去，坚定下未来。
谈过去 从研究生说起，研究生三年时间，基本上全部扑在科研上了。由于本科是学数学的，研究生期间做图像检索，机器学习。而毕业的时候 并没有选择读博，而是去了华为，做网络通信相关的产品。做了三年后，跳槽去了南京的SAP，做ERP，Java、前端。 不难发现六年的时间里其实跨越了两个领域，从传统的通信软件到业务驱动的ERP解决方案，而研究生三年的机器学习经验并没有在 实际工作中给我带来帮助。
研究生三年，心思都扑在了科研上，做论文，看新的算法实现，找到改进点然后再写论文，如此往复。以至于在研二暑期的时候感觉一度抑郁。 为什么会有这样的反应，因为写论文确实很劳神费力，并且往往碰到过很长一段时间才能明白的理论和算法。所以三年下来真的很辛苦。 毕业的时候，也很想找个相关的工作，例如机器学习、图像检索，无奈那个时候机器学习或者说人工智能并没有现在这么火，可供选择的 机会也寥寥无几。毕业的时候也对自己的研究厌倦了，因为发现实际当中应用并不广泛，做的太多也不会带来实际价值，便放弃了科研之路， 踏上了华为的奋斗之旅。
华为的三年真的是奋斗者的三年，作为人生的第一份工作，华为还是给了我很多。工程商人的思维，技术人员也要有，客户至上等等。 很多职业素养和规范，有了自己的理解。拼搏了三年学到了很多，成长了很多。忘记了多少个通宵达旦，夜以继日的修改版本等待上线。 多少个开工会，多少个项目组聚餐。。。
还是要感谢华为的那些老师傅，又很多技术大牛，也有很多销售精英。华为还是非常锻炼人的地方，呆了三年，不能说是完美毕业，也算得上是合格毕业吧。
比起华为来，南京SAP还是有大外企的风范。不再需要急急忙忙打卡了，不那么闭塞，open自由了很多。可以有空闲时间好好研究下自己喜欢的东西。 眼界开阔了许多。技术方面弥补了很多层面。
谈现在 回顾这段六年的工作经历，跨越了软件开发的方方面面。在华为进行着较为底层的C++研发，例如Linux、协议解析，网络通信，Linux内核模块也写过。 华为的三年为以后的软件研发打下了坚实的基础。SAP的工作，又偏向于前端，ERP应用，纯业务层的研发，所用的技术也感觉变得简单起来。 Java、PHP、JavaScript，CSS。其中也用golang实现了几个实用工具。对自己希望再好好打磨一下，不管是从技术上还是从管理上。
想象一下以后 技术人员的出路问题，网上已有很多讨论。每个人都有自己的路，不管怎样，尽力就好。技术上还要从广度和深度上多下功夫。回想过去的将近六年工作， 自以为还是勤勤恳恳，脚踏实地的。这个行业每几年都会有不同的热点出现。比如刚毕业的时候其实通信行业已经不太好了，而互联网却是方兴未艾， 没有达到最近几年的的火爆程度。跟随一个火爆的行业就像踏上了一艘巨轮，不出太多意外，自己差不多也会功成名就。
而现如今，机器学习和人工智能变成了一个新的风口，归功于很多成功的模型，成功的应用，让大家都能享受到机器学习、大数据处理带来的有利分析结果。 而自己研究生三年的研究工作，现如今已有很多成熟的应用面世，例如图像检索、人脸识别。所以也计划从现在开始有时间，就开展些研究，争取做些成功的 机器学习应用，说不定哪天做出个成功的原型呢。</description>
    </item>
    
    <item>
      <title>RabbitMQ and ElasticSearch</title>
      <link>http://www.heguangnan.com/post/rabbit-elastic/</link>
      <pubDate>Fri, 06 Jan 2017 17:08:03 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/rabbit-elastic/</guid>
      <description>项目需要产品中引入了ElasticSearch，第一阶段的使用场景是直接消费RabbitMQ来persist相关的业务数据，改变以前通过message driven走API Call 的方式persist数据。调整过后性能提升了一个数量级。第二阶段将会使用ElasticSearch作为产品的全文检索引擎使用，类似于Search加速组件。 在这个过程中开发了不少原型代码，也做了一系列的笔记，项目是elastic-rabbitmq，相关的notes：
 ElasticSearch 深入理解 一：基础概念&amp;amp;源码启动 ElasticSearch 深入理解 二：乐观锁&amp;amp;版本冲突管理 ElasticSearch 深入理解 三：集群部署设计  项目继续，也会持续更新。</description>
    </item>
    
    <item>
      <title>kubernetes start</title>
      <link>http://www.heguangnan.com/post/kubernetes-start/</link>
      <pubDate>Mon, 15 Aug 2016 13:57:02 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/kubernetes-start/</guid>
      <description>先从几个概念理解开始：
Pods 是一个container的集合，针对特定应用服务的建模，一个或者多个容器分布于相同的物理主机或者虚拟主机。位于相同pod的应用是共享存储的。容器位于相同的pod，共享IP address 和端口空间。类推到docker上，就是pod定义了一组containers。跟单个container部署类似，pods的生命周期也是跟随宿主node的。
pod建模于多个相互合作的进程，整体表现为一个内聚的service。pod作为部署的独立单位，支持水平扩张，复制等，共享各种相互依赖的资源。使用pods会有诸多好处：
 透明化，pod中的容器在基础框架中变得可见，为提供各种服务提供了便利。 解耦，pod中的容器可以被重新构建和升级。 容易使用。 高性能，基础框架会统一处理容器的管理。 Pod的生命周期，通常情况下，用户不需要直接去创建pod，应该只有通过controllers RC来创建。  RS &amp;amp; RC Replica Sets 和 Replication Controller
Replica Sets 是 Replication Controller的升级概念，共同的使命都是管理pod，让他们高可用。名字上也透漏了这一点，复制集。但是着两种东西基本都不会用，建议使用其更上层的deployment。这里还是看你的服务是通过什么方式部署的，是否通过deployment。
Deployment 一个Deployment提供了更新Pod和Replica Set的机制。通过Deployment可以创建新的resource和替换已有的resource。 常用的方法，更新deployment中的image，让其开始做rolling-update。deployment 是在实际使用中使用较多的API。
Services k8s中的service是构建在Pods之上的逻辑概念。打通Pods之间的通信。service正好建模于微服务。对于Service的endpoints对应于Pods，pods通过selector 确定。
Resource management k8s的强大之处在于管理集群中的资源，提供了方便的接口。升级、回滚等等。链接中的命令通过kubectrl提供，可以多多操作练习。
Volumes volumes提供了一种持久化数据的功能，能够跨pods使用。有很多类型的volume可用。
还有其他非常有用的概念：Namespaces，Job。
实用操作 下面总结下平常使用较多的kubectl命令； 先看配置:
➜ ~ cat ~/.kube/config apiVersion: v1 clusters: - cluster: server: http://10.58.80.171:8080 name: demo - cluster: server: 10.58.117.209:8080 name: dmz - cluster: server: http://10.58.113.74:8080 name: hypercd - cluster: server: 10.</description>
    </item>
    
    <item>
      <title>Book Review: Thinking in Java</title>
      <link>http://www.heguangnan.com/post/book-review-thinking-in-java/</link>
      <pubDate>Tue, 26 Jul 2016 09:50:57 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/book-review-thinking-in-java/</guid>
      <description>Reading Book 断断续续的看了将近一个多月，算是系统复习下，一来不能让书白买了，二来毕竟很长一段时间没有做过大规模的Java开发了，Java还是很有意思的，后面还会有很多Book Review。 需要说明的是，后面几个章节没有什么笔记。原因是他们都太工程化了，需要更多的实践，就没再记录。后面尽量每个topic都有单独的blog。 学无止境
第五章 初始化与清理  根据参数列表不同进行函数重载，无法根据返回值进行函数重载。因为函数调用者不关心函数的返回值，编译器就无法判定。参数列表的不同顺序也能区分不同的函数，但是这样维护性不够好，不建议这样做。 如果自己类里面已经定义了一个构造器，无论是否有参数，编译器都不会再生成默认的构造器了，跟C++一样。 this 关键字代表当前对象，可以用this调用一个构造器，但是不能同时调用两个；也必须将构造器调用置于最开始的地方，否则编译器会报错。 finalize 用于验证终结条件。垃圾回收和终结，都不保证一定会发生。如果java虚拟机并未面临内存耗尽的情况。  对象可能不被垃圾回收 垃圾回收不等价与析构 垃圾回收只与内存有关。 终结函数要避免使用  在定义类成员变量的地方为其赋值。构造器初始化之前，类成员变量就已经进行了初始化。类内部，变量定义的先后顺序决定了初始化的顺序。即使变量定义散布于方法定义之间，他仍旧会在任何方法被调用之前得到初始化。
 初始化顺序是先静态对象，并只在Class对象首次加载时执行一次； new 分配内存； 执行字段定义处的初始化动作； 执行构造器。  静态初始化只在Class 对象首次加载的时候进行一次。非静态实例初始化，与静态初始化子句一模一样，只是少了static关键字。这种语法对于支持匿名内部类的初始化是必须的。 实例初始化字句：
   class Mug { Mug(int marker) { print(&amp;quot;Mug(&amp;quot; + marker + &amp;quot;)&amp;quot;); } void f(int marker) { print(&amp;quot;f(&amp;quot; + marker + &amp;quot;)&amp;quot;); } } public class Mugs { Mug mug1; Mug mug2; { mug1 = new Mug(1); mug2 = new Mug(2); print(&amp;quot;mug1 &amp;amp; mug2 initialized&amp;quot;); } Mugs() { print(&amp;quot;Mugs()&amp;quot;); } Mugs(int i) { print(&amp;quot;Mugs(int)&amp;quot;); } public static void main(String[] args) { print(&amp;quot;Inside main()&amp;quot;); new Mugs(); print(&amp;quot;new Mugs() completed&amp;quot;); new Mugs(1); print(&amp;quot;new Mugs(1) completed&amp;quot;); } } /* Output: Inside main() Mug(1) Mug(2) mug1 &amp;amp; mug2 initialized Mugs() new Mugs() completed Mug(1) Mug(2) mug1 &amp;amp; mug2 initialized Mugs(int) new Mugs(1) completed   可变参数列表：void f(Object&amp;hellip; args),除了Object之外，其他的数据类型也可以作为可变参数列表。  第六章 访问权限控制  访问权限等级：public，protected，包访问权限，private。 一个java源文件为一个编译单元，每个编译单元只能有一个public类。java可运行程序是一组可以打包压缩为一个java文档文件的.</description>
    </item>
    
    <item>
      <title>人生不是演出</title>
      <link>http://www.heguangnan.com/post/%E4%BA%BA%E7%94%9F%E4%B8%8D%E6%98%AF%E6%BC%94%E5%87%BA/</link>
      <pubDate>Tue, 19 Jul 2016 16:55:26 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/%E4%BA%BA%E7%94%9F%E4%B8%8D%E6%98%AF%E6%BC%94%E5%87%BA/</guid>
      <description>最近看了两个电影《遇见你之前》和《初恋这首情歌》。一个关于死亡，一个关于青春，很是巧合。
两部电影都给了我很多很多感动，感动到哭。
死亡一点不可怕，更何况是自己主动选择的呢。当发现自己已经不回不去正常人的生活时，那是多么的绝望，威尔深深的认识到自己的人生不能是这样的，活着有什么意义，为了父母他答应继续多活半年。半年的时间里小露作为护工来到他身边，带给他快乐，同时也意识到平凡人的生活如此。爱又能如何，参加了本来是自己的妻子的婚礼，生老病死人又能如何，家庭殷实他也许会让他活的还算可以，可是不是他的人生。从一个喜欢极限运动，喜欢冒险的人，到一个半身不遂的人，这样的转变，谁又能接受得了。也许已经是大彻大悟了，看尽了世态炎凉，看尽了苦尽甘来。该有了不能有，没有的终究也是没有。
人越到老就越怕死，会是这样的吧。年轻人无所谓，能够看尽人生也许本身比活的更久的人知道什么是重要的。需要的是什么的，自己的人生是什么。 关于青春，都有很多希望和机会，每个人都可能会有大的作为。《初恋这首情歌》已经超出了初恋的范畴，讲了很多关于人生的思考，带给人很多深思，也许这就是这部电影能拿高分的原因吧。
那就让我们思考一下。
康纳因为看上了一个女孩，因为女孩非常想当模特，康纳要组建乐队让他在MV可以当模特。组建了乐队，开始了歌曲创作。事情也会发展会很顺利，可是现实不容的半点马虎。康纳父母不合，将要离婚，哥哥因为早年带着梦想想出去闯荡，却被父母强行的留在了身边，导致了哥哥的颓废。电源中有很多镜头都是展示他是多么的颓废和失望，所以他最不希望他的弟弟步他的后尘。这也是电影最后所要表达的，很有杀伤力的情感。
康纳的歌都是为他心爱的姑娘所写，所以演出的时候多么的希望她的出现，不仅如此，他还希望父母是恩爱的，并能结伴来看他的演出；还有他的哥哥，希望他能重振旗鼓意气风发的来看他的演出，也希望同学、老师都是和蔼可能一群人；当然最最希望的是他心爱的姑娘跟他的不靠谱男朋友分手。。。可是演出结束回到了现实，发现一无所有了。父母要离婚、心爱的姑娘离开去了英国、哥哥还是那样的自暴自弃。这就是现实，让人喘不过气来。
好在电影最后有了反转，心爱的姑娘受伤回来了，康纳还在继续他的歌曲创作。最后一起出逃，离开这里，因为这里只会让才华腐烂、让人颓废并变成酒鬼。康纳的哥哥带他们走了最后一段路，从最后他那欲言又止的表情，可以深深的感受到，康纳是对的，因为他年轻的时候就该这样的出逃。他是欣慰的。
以史为镜，人人都有一个过去。但人生不是演出，更不会顺着你的希望发展，因为这是现实。</description>
    </item>
    
    <item>
      <title>读书：微服务设计</title>
      <link>http://www.heguangnan.com/post/%E8%AF%BB%E4%B9%A6%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Wed, 01 Jun 2016 13:32:34 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/%E8%AF%BB%E4%B9%A6%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1/</guid>
      <description>就是这样的一本书，来的非常及时。
总体认识 微服务绝不是什么新技术或者新框架之类的，就算概念也不是新的。没有看书之前或许会认为微服务是中心化新的架构模式，看书后会发现其实微服务是个生态圈。 为什么会这么说，他是什么样的生态圈。或许这是整个软件行业的生态发展趋势，比如SaaS软件已在某些领域获得巨大成功，其背后的支撑技术跟微服务有莫大的关联。 微服务是个生态，围绕这样的生态圈有强大的技术支撑。例如微服务的部署、监控、发现、故障处理、负载均衡、扩展、安全、高可用性、自动化测试等等。这些技术都不是新技术， 或许就因为这些技术发展到一定程度后的一次整体升级换代，相比传统的单块软件部署开发模式，这些技术面临的挑战或许更让人激动人心。
书中最后总结得出微服务的原则： 微服务自治的小服务微服务&amp;lt;div&amp;gt;自治的小服务&amp;lt;/div&amp;gt;围绕业务概念建模围绕业务&amp;lt;div&amp;gt;概念建模&amp;lt;/div&amp;gt;自动化的文化[Not supported by viewer]隐藏内部实现细节隐藏内部&amp;lt;div&amp;gt;实现细节&amp;lt;/div&amp;gt;一切都去中心化一切都去&amp;lt;div&amp;gt;中心化&amp;lt;/div&amp;gt;独立部署独立部署隔离失败隔离失败高度可观察高度可观察
七个原则都有较好的指导性，在践行微服务前，先对照看下能否满足这七条原则。下面从头开始梳理、认识下微服务的设计过程。
微服务 概念先行这个很重要，任何学科都是。 微服务定义： 1. 很小，专注于做好一件事情。内聚性很重要，微服务需要有很好的内聚性，即做到因相同原因而变化的东西聚合到一起，而把不同原因而变化的东西的分离开来，这也是专注的含义。 多小才算小，一个微服务可以在两周内重写掉。服务越小，独立性带来的好处就会越多，而同样服务管理也会越复杂。 2. 自治性。独立部署，通过暴露API，使用网络通信，避免紧耦合。需要正确的建模服务和API。
演化式架构师 本章讲解了如何去做一个合格的架构师。这个对于一个架构师或者将要成为架构师的人来说很有指导意义，特别是面临微服务架构演进时。
测试 测试类型定义： 验收测试我们是否实现了正确的功能？自动化测试 Fit-Finess[Not supported by viewer]面向业务面向业务支持团队支持团队评价产品评价产品面向技术面向技术探索性测试可用性测试：我如何破坏系统功能手工
[Not supported by viewer]单元测试我们是否正确地实现了功能自动化的 xUnit系列单元测试&amp;lt;div&amp;gt;我们是否正确地实现了功能&amp;lt;/div&amp;gt;&amp;lt;div&amp;gt;自动化的 xUnit系列&amp;lt;/div&amp;gt;非功能性测试响应时间；可扩展性；性能测试；安全测试工具[Not supported by viewer]
深入微服务之前，首先要解决的就是自动化的测试。
测试范围  单元测试：是帮助开发人员的，是面向技术而非业务的。单元测试对于代码重构非常重要。 服务测试：绕开用户界面，直接对服务的测试。测试单独的服务，可以提高测试的隔离性，这样可以更快的定位解决问题。 端到端测试：覆盖整个系统，是需要通过浏览器操作图形用户界面。  实现服务测试 打桩还是mock，打桩是指被测试服务的请求创建一些有着预设响应的打桩服务。mock还会进一步验证请求本身是否被正确调用，也可以用来验证预期的副作用是否发生。
脆弱的测试 随着测试范围的扩大，纳入测试的服务范围也会变多，这样测试失败的可能性就会更大。
拯救消费者驱动的测试 端到端测试试图解决的关键问题，就是确保部署新的服务到生产环境后，变更不会破坏新服务的消费者。一种不需要真正的消费者也能达到相同的目的：CDC，Consumer-Driven Contact 消费者驱动的契约。使用CDC时，我们会定义服务（或生产者）的消费者的期望。这些期望会变成对生产者运行的测试代码。 PACT 是一个消费者驱动的测试工具。 工作流程：
对其运行对其运行使用PACT DLS定义的期望使用PACT DLS定义的期望PACT mock服务器PACT mock服务器消费者端消费者端生成消费者规范生成消费者规范PACT brokerCI/CD工具的构建物仓库PACT broker&amp;lt;div&amp;gt;CI/CD工具的构建物仓库&amp;lt;/div&amp;gt;存储在存储在Pact HelperPact Helper生产者生产者获取自获取自生产者端生产者端使用PACT规范调用使用PACT规范调用
后面会补充下实践经验。
如果建模微服务 好的微服务的定义：高内聚，松耦合。从而引出服务边界的问题。
限界上下文  共享的隐藏模型； 模块和服务 过早划分  边界问题如何划分；基于业务功能、还是技术边界。本章主要是一些概念的陈述。</description>
    </item>
    
    <item>
      <title>SaaS DataBase</title>
      <link>http://www.heguangnan.com/post/saas-database/</link>
      <pubDate>Sun, 29 May 2016 14:34:35 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/saas-database/</guid>
      <description>距离上次日志已有将近半年的时间，由于经历了很多工作上的事情，少写了日志，算是自己的疏漏吧。后续要多写几篇，把最近落下的补上。
为什么会写这样的一篇日志，一来是公司最近推行MSA，即微服务化，现在很多公司都在推行，各种大会大家都在述说着自己的优秀实践。二来自己目前做的工作与数据存储有很大关系，由于之前的方案也存在着诸多问题，需要做些改变了。这里就记录下来看看心理路程吧。
SaaS的概念已经出现很久了，至少10年前就已经很热了。但关于这个概念的背后，至今大家都在沿用着，个人喜欢的一个图：

上图出自于Architecture Strategies for Catching the Long Tail，这里针对图的内容再做些介绍。 图中展示了SaaS软件的发展方向，其实原意是SaaS的成熟度模型，实质也是SaaS软件的发展方向。而软件的发展最终会向SaaS软件靠拢，毕竟在发展的过程中资源会不断的优化配置，社会分工也会更细。这样管业务的就专心做好业务了，管资源管理的就专做资源管理，必须大型的PaaS平台等等。云计算本质上也是一个意思，把自己的软件部署到云上，管理维护的负担就没有了，交给了专门负责那方面的第三方合作伙伴。ok，回到图上。
 第一象限：就level 1，表达的就是定制化软件，其与传统的软件并没有太大区别。对于不同的tenant都不同的应用主机。 第二象限，configurable， 即应用主机会是同一份但是针对不同的tenant会有不同的配置，通过大量的配置来实现不同用户的需求。主机是隔离的，每个tenant独享一台 第三象限，configurable，multi-tenant 有效的，处于第三level成熟度的SaaS服务，使用同一台主机服务所有用户。因为共享一台服务，合理的降低了成本，通过metadata实现定制化。这里最大的缺陷就是扩展性问题，因使用同一台主机遇到性能问题只能更换到更强大的server上面。 第四象限，合理解决了第三象限的问题，即扩展性问题。通过一个负载均衡器对所有的主机进行负载均衡，每个tenant根据不用的metadata实现私有化。这样的结构可以支撑更多的tenant，并能有效的降低成本。将会是所有SaaS服务商最终的实现方案。  由于本文要讲的是database，所以请将上述中的主机换成DB 主机，不同的tenant不同的metadata，这也对应着tenant的DB。让我们步入正题，怎么样才是更合理的SaaS 数据库，又如何实现？ 其实针对SaaS的数据库服务，还有个概念DaaS，Data as a service，它是SaaS的表亲，目前也有很多云计算公司提供这样的服务，当然这是宏观上的，这里就关注下如果让自己是实现应该怎么做。 目前互联网大部分的架构都是LNMP，mysql作为存储服务器，怎么让mysql变得可以扩展，并保持高性能，是SaaS软件必然要解决的问题，即实现上述的第四象限。
实现SaaS的database，最好就是DaaS了，但是做到DaaS是比较困难的，需要部署、监控、配置自动化，failover和动态伸缩等等。所以目前比较常用的是中间件技术。比如360的Atlas，阿里的cobar。这些中间件都有一些共同也是中间件主要要解决的问题：
 连接池，MySQL服务器在高并发下性能会很差，因为每个连接mysql都会启动一个线程处理，连接池通过连接复用会大大减轻MySQL服务器的负担。 分库分表，这项功能解决了扩展问题，MySQL的单表只能支撑百万级别的数据，有上千万甚至亿、几十亿等级别的数据单表是无法存储的。通过中间件将表存储到多个MySQL server中，还要支持查询结果从多个数据库实例做归并。 升级、负载均衡，proxy后台有多个MySQL的实例，每个instance其实也是个cluster，升级时势必要关停一中一个，则请求会被迅速转移到cluster中的其它主机上。负载均衡更是一种基础功能，每个请求会被负载均衡分发到cluster中。 读写分离，个人认为这是比较重要但不是必须的。cluster中做负载均衡即可，大部分的场景还是读多写少，完全放在一个instance上也不会有问题，读写分离还是会有不少的兼容性问题。 监控，运行状态等，监控各个节点的运行状态，并自动记录慢查询等，输出runlog，供DBA查看。  如果一个中间件能完美的做到上述5点，应该就能胜任SaaS的数据存储了。</description>
    </item>
    
    <item>
      <title>input 和 textarea的长度限制问题</title>
      <link>http://www.heguangnan.com/post/input-%E5%92%8C-textarea%E7%9A%84%E9%95%BF%E5%BA%A6%E9%99%90%E5%88%B6%E9%97%AE%E9%A2%98/</link>
      <pubDate>Thu, 28 Jan 2016 21:48:40 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/input-%E5%92%8C-textarea%E7%9A%84%E9%95%BF%E5%BA%A6%E9%99%90%E5%88%B6%E9%97%AE%E9%A2%98/</guid>
      <description>一些敏感的页面应用，对用户的输入都有较多的限制，长度便是其中之一。但是最近遇到一个长度限制的问题。HTML对 input 和 textarea都有maxlength 的属性，该属性的解释就是允许输入字段的最大字符数。这里说的字符数，对英文是完全没有问题的，能做到精确控制输入长度，但是汉字的长度就会有前后不一致的问题。
编码问题 互联网上使用最为广泛的就是UTF-8的编码方式，查看网页源码的时候基本上都能看到字符集的编码设置：
&amp;lt;meta charset=&amp;quot;utf-8&amp;quot;&amp;gt;  UTF-8是Unicode的一种实现方式。是一种变长编码，想更多了解的可以看这篇文章，基本上能让大家明白。所以造成这个问题的主因也是由于变长编码导致的。javascript把每个汉字当成一个字符，而在后台PHP是按照UTF-8计算，每个汉字由三个字节组成，故中文输入到了后台长度会变成字数的三倍。所以在输入框里面有中文的时候maxlength限制就不再可靠了。
精确获取字符长度 由于maxlength不再可靠，需要有方法获取任意输入的字节数。针对中文输入使用将其转码并使用特殊方法计算其长度便可达成精确控制输入长度的目的。encodeURIComponent方法是比较好用的：
The encodeURIComponent() function encodes a Uniform Resource Identifier (URI) component by replacing each instance of certain characters by one, two, three, or four escape sequences representing the UTF-8 encoding of the character (will only be four escape sequences for characters composed of two &amp;quot;surrogate&amp;quot; characters).  该方法能将UTF-8编码的输入文字转码成对应的多字节字符串。 例如：
encodeURIComponent(&#39;我的问题&#39;) &amp;quot;%E6%88%91%E7%9A%84%E9%97%AE%E9%A2%98&amp;quot;  每个中文字转成三个字节冠以%开头。匹配出这样的pattern并计算长度，使用javascript的正则表达式:
/%[A-F\d]{2}/g  并临时替换成一个英文字符，那么长度就可以准确得到了：
encodeURIComponent(&#39;abc我的问题abc&#39;).replace(/%[A-F\d]{2}/g, &#39;i&#39;) &amp;quot;abciiiiiiiiiiiiabc&amp;quot; encodeURIComponent(&#39;abc我的问题abc&#39;).</description>
    </item>
    
    <item>
      <title>系统性能 一</title>
      <link>http://www.heguangnan.com/post/%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD-%E4%B8%80/</link>
      <pubDate>Sun, 17 Jan 2016 21:48:25 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD-%E4%B8%80/</guid>
      <description>最近一直在做系统性能优化，包括性能问题定位，系统整体性能提升等。在性能测试环境上一边测试一边优化，从最开始的表象开始，修改代码和各种系统参数，然后就会出现新的表象，然后再修改代码和系统参数。性能测试涉及的节点很多，很多方面都有联动性，最后辛辛苦苦的搞了大半个月，确实有所进展但是总感觉缺少系统的方法。今天有幸看到这样的一篇文章Linux Performance Analysis in 60,000 Milliseconds，明确了在一个server上面，最开始你应该关注到什么。虽然里面的东西大家都有注意，但是可能还是不够全面。现在就结合这篇文章和自己的实践做下总结吧。
uptime 首先出场的便是uptime这个命令：
root@ip-172-31-3-207:~# uptime 02:15:06 up 48 days, 18:01, 3 users, load average: 65.43, 17.08, 5.81  这个命令明确告诉我们当前系统的时间，启动运行了多长时间，用户的登录数，以及当前系统分别在 1，5，15分钟内的进程平均数量，这些进程数量表示运行中或者处于不可中断的状态。这个命令是非常high level的总结，说明总体的系统负载情况。
dmesg|tail 个人比较喜欢这个dmesg命令，一般是内核的日志，会有一些重要的信息抛出。例如进程异常退出，因为内存耗尽或者进程crash。还会记录些命令操作的异常。值得好好利用的命令。
vmstat 1 系统虚拟内存的统计信息，1表示没1秒输出一次。
root@cnpvgvb1od042:~/PCP# vmstat 2 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 9818904 1820 3563052 0 0 0 2 0 0 0 0 100 0 0 1 0 0 9842332 1820 3563104 0 0 0 98 4195 6788 41 4 55 0 0 0 0 0 9888940 1820 3563124 0 0 0 0 1886 3149 15 2 83 0 0 5 0 0 9917440 1820 3563104 0 0 0 0 3549 6524 31 4 66 0 0 15 0 0 9961216 1820 3563156 0 0 0 34 6469 11150 70 8 22 0 0 5 0 0 9998920 1820 3563236 0 0 0 0 4350 7398 49 5 45 0 0 2 0 0 10038652 1820 3563260 0 0 0 58 2922 4788 28 3 69 0 0 4 0 0 10070480 1820 3563244 0 0 0 1252 2305 4215 14 2 84 0 0 1 0 0 10100696 1820 3563284 0 0 0 0 2683 4405 14 2 84 0 0  几个重要的列： r: 正在运行或者等待运行的进程数。该数量不包含I/O的进程。CPU是否饱和，就看这个数量是否多余CPU核的数量。 free:剩余内存以kb为单位。 si，so：换入换出，如果这些值非0，那么说明内存不足。 us, sy, id, wa, st: 这几项表明当前CPU的繁忙程度。分别代表了用户时间，系统时间，空闲时间，wait IO时间和stolen time。需要注意的是system time也有IO处理的时间。如果比较高的系统时间占用说明内核处理IO不够高效。</description>
    </item>
    
    <item>
      <title>Apache Cache 研究</title>
      <link>http://www.heguangnan.com/post/apache-cache-%E7%A0%94%E7%A9%B6/</link>
      <pubDate>Wed, 09 Dec 2015 21:48:04 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/apache-cache-%E7%A0%94%E7%A9%B6/</guid>
      <description>Apache 作为一个hosting server，在2.2版本以上的也有较为强大的缓存功能。使其不管是作为web server还是代理server都能实现访问加速。 Apache支持两种cache模块，分别是mod_cache和mod_file_cache。mod_file_cache较为简单粗暴，cache那种不轻易改变的或者对实效性要求不高的文件较为适合，因为后台更新了缓存不能及时更新，需要一个周期或者重启Apache。 mod_cache是一种较为智能有效的、感知HTTP协议的cache方式，它有两种实现方案mod_mem_cache和mod_disk_cache，顾名思义mem是将响应内容缓存到内存中，disk是将响应内容缓存到磁盘中。mem是代价比较高的，因其缓存到内存中就会不可避免的导致Apache占用的系统内存增加。因此disk的缓存方案多被推荐使用。 具体详细的信息可以参考Apache的官方文档Caching Guide
浏览器刷新原则 不同的请求header，cache的响应行为是不一样的，所以要搞清楚你的请求header是什么样的，响应header是什么样的，搞清楚才能较好的测试Apache的cache。 这里使用的测试浏览器是Firefox，也推荐使用Firefox，禁止Firefox的本地cache。 一般的请求头，类似点击页面链接：
Accept text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 Accept-Encoding gzip, deflate Accept-Language zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3 Connection keep-alive Cookie timeOffset=-480; timeOffset=-480; wp-settings-time-1=1445853102; PHPSESSID=ohiq63apsjmvsrl443778j22g6; ANW_TRACE_ID=25a6e917-0a0b-4580-a989-14ef71368ea1; CART_ITEMS=%5B%5D Host 10.128.163.72 User-Agent Mozilla/5.0 (Windows NT 6.1; WOW64; rv:42.0) Gecko/20100101 Firefox/42.0  F5 刷新的请求头：
 Accept text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 Accept-Encoding gzip, deflate Accept-Language zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3 Cache-Control max-age=0 Connection keep-alive Cookie timeOffset=-480; timeOffset=-480; wp-settings-time-1=1445853102; PHPSESSID=ohiq63apsjmvsrl443778j22g6; ANW_TRACE_ID=25a6e917-0a0b-4580-a989-14ef71368ea1; CART_ITEMS=%5B%5D Host 10.128.163.72 User-Agent Mozilla/5.0 (Windows NT 6.1; WOW64; rv:42.</description>
    </item>
    
    <item>
      <title>HTTP Cache</title>
      <link>http://www.heguangnan.com/post/web-cache/</link>
      <pubDate>Fri, 27 Nov 2015 17:45:24 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/web-cache/</guid>
      <description>目前估计很少有网站不会使用http cache了，http cache 的合理使用能极大的提高用户体验，另一方面还能减轻server端的负担。特别现在流行https，使用好http cache也变得更加重要了。
相关HTTP header字段 Last-Modified和ETag 两者的功能类似，一个是文件的最近一次的修改时间，一个是针对这个资源文件生成的tag。都是server端的返回。刷新页面时，请求头里面会带上If-Modified-Since或者 If-None-Match。 但是Etag并不推荐使用，原因就是不同的server对Etag的生成算法可能不统一，特别在集群server的情况下。
Pragma 纯协议上的指令，对请求响应链路上的所有代理使用。例如如果pragma：no-chache，则请求在请求响应链上的任意节点都不会被缓存，因其于cache-control：no-chache意义一致。
Expires set response headers，对某个响应设置个超时时间，一般优先级不高，如果存在max-age的话，这个字段几乎不起作用。
Cache-Control public：标识验证后的respons可被缓存的。 no-store：任何情况下不缓存，并尽量不要保存到磁盘中。不缓存的资源并不能保证不被保存到磁盘中。例如浏览器的后退键，可能会导致看到过期的页面。 no-cache: 强制提交校验请求，严格模式，也即不缓存该响应。 must-revalidate: 缓存必须遵守任何的刷新规则，如果缓存超时必须重新发起请求，或者是条件请求。 proxy-revalidate： 和must 一样，只对proxy cache有效，对中间有cache server的情况，该字段指导cache server的验证方式和条件。 max-age: 指定刷新超时时间，即cache的超时时间。 s-maxage: 和 max-age一样，如果cache不是private的，他会指明cache servers使用这个s-maxage，针对public的cache有效，其会覆盖max-age。
vary 通过vary告诉http cache，寻找缓存对象时需要考虑的头域字段。比如：浏览器发了两个request，一个带有accept-encoding， 一个没有。http 缓存的时候会带上这个vary标记，表示只有带有accept-encoding的缓存对象才能是使用。达到的效果就是request里面带有accept-encoding的请求，响应缓存只能被这样的请求获取。
vary的不同会控制请求的发送数量。例如vary:*，表明每个request都是不同的。 简单的理解vary用来区分请求的差别，识别出不同的request。 vary的其他取值：user-agent, 让响应区分不同的agent；Referer, 区分这个request是从哪个页面而来。cookie, 不同认证信息不同的 request。vary指定的那些值就会影响浏览器的cache策略。
需要注意的几个问题 https 证书问题 如果是无效的证书，会导致缓存无法完全起用。本地测试是doc无法被cache，静态资源还是可以的。当然这跟浏览器的行为也有关系，Firefox里面添加例外证书变成合法的就可以正常缓存了。chrome的证书比较严格不好把红叉叉去掉。
expires和max-age 优先级问题 当response头域里面两者都包含时，浏览器会优先选用max-age，当然这是我本地的测试结果。所有的情况可能难以覆盖，比如移动端的浏览器，其他的浏览器，除了Firefox、chrome、IE等等以外的。 另外就是expires是http1.0里面的，max-age在http1.1被引入，但是这篇文章建议最好两者都带上正确的值，或者只带上max-age。
Conditional Requests 条件请求是当浏览器发现资源超时时，如过了max-age或者expires date，会发起条件请求，如果server发现资源变化了会回复200 ok，否则回复304的status code。正确情况下资源cache后，浏览器是不会发条件请求的，直到资源超时后。当然也不排除某些浏览器会不停的发conditional request，更为详细的介绍，请看这里。
静态资源缓存 针对静态资源，更新时更加推荐使用变更文件名的方式，例如让文件名包含一个版本号的方式。这种比文件末尾增加query string更加有效，例如有些中间proxy就不会缓存带有查询字符的url。
PHP配合apache 实现静态资源版本控制 针对静态资源的cache设置，这个github有较好的配置模板做参考。基本上enmod headers即可。 针对静态文件php代码里面插入版本号，一般为时间戳或者数据库里面的更新时间：</description>
    </item>
    
    <item>
      <title>golang interface analysis by gdb</title>
      <link>http://www.heguangnan.com/post/golang-interface-analysis-by-gdb/</link>
      <pubDate>Fri, 23 Oct 2015 22:45:07 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/golang-interface-analysis-by-gdb/</guid>
      <description>interface 在go语言中，是非常重要的一环，总有点让人感到很玄乎不定的感觉。官方的lib中有大量使用，似乎面向对象和动态绑定也能跟interface扯上关系。总之，如果能更好的理解interface的机理，就能更好的理解和使用Go了。
interface的较为深层次的探讨在这篇blog里面已经有较为详细的介绍。但是缺乏一些实践，本文遍结合此文，使用GDB实际研究一下。
interface 内部存储 interface的值，其实是两个指针的组合：data 和 tab。data 实际指向值的指针，tab是go runtime的一个struct：
// layout of Itab known to compilers // allocated in non-garbage-collected memory type itab struct { inter *interfacetype _type *_type link *itab bad int32 unused int32 fun [1]uintptr // variable sized }  在运行时该结构会被runtime库计算出来，保证interface的正常运转。 使用go build -gcflags &amp;ldquo;-N -l&amp;rdquo;编译便可以是用GDB来debug了。 断点断在最后一行代码，代码在最后列出。
(gdb) info locals b = 200 s = {tab = 0x7ffff7e0f1c0, data = 0xc82000a3b0} nothing = {_type = 0x4c1360, data = 0xc82000a430} face = {tab = 0x0, data = 0x0} any = {_type = 0x4e4a80, data = 0xc82000a3c0}  首先看变量*s*，内部有个tab指针和data指针。</description>
    </item>
    
    <item>
      <title>So Busy</title>
      <link>http://www.heguangnan.com/post/so-busy/</link>
      <pubDate>Wed, 05 Aug 2015 20:45:07 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/so-busy/</guid>
      <description>最近几周，有点回到华为的感觉了，没想到在大外企也有这么紧张的时候，但主要是部门管理完全掌握在国人手里。 整理下最近都是忙了点啥。 由于产品定位是个电商平台，那么前端theme的开发其实变得不是那么的重要了，重要的是后台能力的构建。也就是提供足够强大、灵活的接口供前端消费，这个重构的过程就是要满足这个定位了。 这其中有个恶心的地方就是本来平台开发是基于wordpress的，而wordpress本身是个开箱即用的东西，完全不是MVC的框架。但需要提供的接口要满足REST Ful 的。所以很多url 的route 规则需要自己去实现。这样下来发现如果最早使用一个PHP的MVC框架会省不小心啊。 好在这个过程需要研究下PHP的MVC框架，为后续的演进做好了铺垫。 另外一个项目就是需要开发自己的CMS系统，这个系统以OPEN API为基础。框架采用后端Java Spring， 前端使用angularJS。 由于对java确是使用的较少，什么java框架也没玩过，所以就聚焦在了angularJS上了。angularJS是前端的MVC框架，能力出众。值得深入研究使用。最起码javaScripts方面的知识派上用场了。</description>
    </item>
    
    <item>
      <title>前端经验</title>
      <link>http://www.heguangnan.com/post/%E5%89%8D%E7%AB%AF%E7%BB%8F%E9%AA%8C/</link>
      <pubDate>Wed, 05 Aug 2015 20:45:07 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/%E5%89%8D%E7%AB%AF%E7%BB%8F%E9%AA%8C/</guid>
      <description>最近还是比较忙，blog好久没有写了，当然也不排除自己有点懈怠。也没有什么太多要写的，就是些工作上的事情。最近做前端比较多，还是就写写前端的一些经验吧。之前也说过，前端就是一个积累的过程，另外多借鉴一些成熟的前端框架会对自己的水平提高很有帮助。
CSS相关 因为开发是基于LESS的，所以代码相关的都是LESS的代码。 ##mixin 可以看作是面向对象的CSS，直白的讲就是混合引入，也有翻译是混入或混合，这样感觉都是很模糊的。其实功能上就是定义一组属性、style在一个mixin中，可以让其他的class直接引用，作为公共的基础class。例如：
.ellipsis (@width) { width: @width; overflow: hidden; text-overflow: ellipsis; white-space: nowrap; }  这个ellipsis class会将定宽文本进行截断，这样的class可能会在网站中多处使用，而且每次使用宽度可变，这样在使用时传入想要宽度的参数即可。例如产品名字的class：
product-name { .ellipsis(8em); ... }  media 由于前端一直在使用bootstrap，所以所有的responsive相关的design都是依赖bootstrap来实现。bootstrap的栅格系统需要一定的使用规则，有的时候过度使用会导致DOM结构过去复杂化了。例如其中的form，form里面必须按照一个input一个label的排列，如果想要添加一些文本信息或者增加其他的标签，又让他保持responsive，必须通过类似row下的col再嵌套row和col，这样就实现很复杂，让DOM结构看起来混乱不堪。 其实看看bootstrap.css里面的代码也不难发现，其实responsive的代码也不难写，问题是你不需要去写一个框架，框架的代码是普适的。你只是为了满足一个小特性，所以代码也会写的很精简。
使用media query 来索引屏幕尺寸并进行特定class的apply。可以让网页支持较好的自适应性。例如针对小屏幕某个class需要有些自适应的属性，下面这个css class在小屏幕上，屏幕宽度小于767px时，左侧增加20px的margin。
.class-name { @media(max-width: 767px) { margin-left: 20px; ... } }  上面是在class里面进行屏幕适应，更多的时候是定义整个class为自适应：
@media only screen and (max-width: 767px) { .class-name { ... } }  根据不同的尺寸class里面的style进行相应的变化。bootstrap也是这么玩的。 在移动设备上有横屏和竖屏的区分，也能做相应的自适应。 关键的属性：
| media 属性 | 结果| | &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;- |:&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-:| | min-width | 当任意浏览器宽度大于查询中定义的值时适用的规则。 | | max-width | 当任意浏览器宽度小于查询中定义的值时适用的规则。 | | min-height | 当任意浏览器高度大于查询中定义的值时适用的规则。 | | max-height | 当任意浏览器高度小于查询中定义的值时适用的规则。| | orientation=portrait| 高度大于或等于宽度的任意浏览器适用的规则。相当于竖屏。| | orientation=landscape| 宽度大于高度的任意浏览器适用的规则。相当于横屏。|</description>
    </item>
    
    <item>
      <title>PHP 框架之CodeIgniter &amp; Laravel</title>
      <link>http://www.heguangnan.com/post/php-framework/</link>
      <pubDate>Sat, 18 Jul 2015 18:45:07 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/php-framework/</guid>
      <description>说明 最近产品考虑更换前端框架，重点考察了CodeIgniter 和 Laravel两个框架，现对其进行下对比分析。
总体对比     CodeIgniter Laravel     Document Good enough Good enough   Performance 差不多 3倍于 Laravel    MVC Good enough Good enough   TWIG 自己添加 TWIG lib 使用三方插件   third-party 自己添加，放到指定目录 composer managment   Route default mapping ：&amp;rdquo;example.com/class/function/id/&amp;rdquo; can be remap, more code than Laravel Simple and clear   summary 简单 精巧 易用，更为丰满    CodeIgniter 基本上是个MVC的空架子，代码量极小，开发的花基本上 100%的掌控在自己手里。 Laravel还是加载了不少的三方 component，比CodeIgniter 庞大些。 对MVC的支持都很清晰，URL的路由也很简单易扩展。</description>
    </item>
    
    <item>
      <title>Go Go</title>
      <link>http://www.heguangnan.com/post/go-go/</link>
      <pubDate>Thu, 09 Jul 2015 17:45:07 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/go-go/</guid>
      <description>最近在学习Go语言。认识Go语言是个偶然，首选是Docker容器的使用，Docker的兴起目前可谓风生水起，应用部署和各种云平台都在推行。其使用Go语言开发，之前没有听说过的。断断续续的找相关的博客、资料进行了解。发现Go 是有很多吸引人的地方，自己非常感兴趣，最近买的一本《Go Web编程》今天到手了。
也说下自己的缘由，很多人都说Go 很容易上手，这应该对C系的开发人员而说的，Go语言的发明者也是C语言的作者，Go语言本身很多的语法、类型、结构等用法类似于C语言，如果编译运行的话二进制文件都能用GDB进行调试。Go语言是个集大成者，在里面你能看到或者重新认识一些语言特性，它有诸多动态语言特有的特性。
 首选想说的就是函数闭包，闭包函数在JavaScript里面应用的最广泛，用于各种回调处理、变量的scope控制等，在Go语言里面也有，使用起来几乎没有什么差别，也能当成变量传递等等。 内置强大的数据结构，例如slice、map，开发的快捷易用性可以和Python媲美。slice 类似于Python、PHP里面的array，map也和Python里面的字典。 interface的类型使用，interface让Go有了面向对象的能力，interface是非常有魔力的东西，应该会是非常广泛的，把面向对象的能力放大了。Go里面的反射功能也是依赖于interface，这篇文章Go Data Structures: Interfaces有较深入的讲解。 并发编程的支持，可以写并发执行的代码，通过go关键字来完成。goroutine确是是个好东西，用户层上的并发协程，能有效的利用多核计算能力。Go能原生的支持并发编程并能很好的利用多核能力是个极大的优势。  有人说不能把Go作为偏向Web的语言，这应该是比较片面的。就像Python一样，一直都是当成工具使用，能快速的开发一些小工具，而现在呢，Python的Web框架为Python的流行应该是起了主要作用。Go的使用应该要偏向云平台开发、Web开发，高性能、高并发的场景。试想下Docker的流行，国内七牛公司对Go语言的推崇。
Go相对于PHP、JAVA年轻很多，但自己相信它会成为后起之秀，也做好了这个准备。
很高兴开启Go语言之旅。</description>
    </item>
    
    <item>
      <title>WEB 开发点滴</title>
      <link>http://www.heguangnan.com/post/web-tech-1/</link>
      <pubDate>Tue, 07 Jul 2015 20:45:07 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/web-tech-1/</guid>
      <description>&lt;p&gt;WEB开发错综复杂，很多知识点让你抓不到重点，用过了忘记了，下次用还要重头开始。例如CSS，很多class，很多的取值，每个都有很多视觉效果。拿到UX的design，不同的人做出来的效果可以保持一致，但是对应的CSS和JS可能完全不一样。正是这种WEB开发的灵活性，更让人抓不到重点。&lt;/p&gt;

&lt;p&gt;最近又在做一些UI的开发工作，集中在前端，需要CSS和JS，事情做完了，仔细想想里面用到的CSS class都理解了吗？发现并没用。如此众多，如何才能掌握这些class呢？突然想到CSS class虽然众多但是用到的不是全集，所以在学习上也要化整为零，化繁为简，各个击破。这次就好好记录下CSS中的overflow和position类。&lt;/p&gt;

&lt;h1 id=&#34;position&#34;&gt;POSITION&lt;/h1&gt;

&lt;p&gt;解释说明：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;position
    
&#39;position&#39;
Value:  
static | relative | absolute | fixed | inherit
Initial:  
static
Applies to:  
all elements
Inherited:  
no
Percentages:  
N/A
Media:  
visual
Computed value:  
as specified
The values of this property have the following meanings:
static
The box is a normal box, laid out according to the normal flow. The &#39;top&#39;, &#39;right&#39;, &#39;bottom&#39;, and &#39;left&#39; properties do not apply.
relative
The box&#39;s position is calculated according to the normal flow (this is called the position in normal flow). Then the box is offset relative to its normal position. When a box B is relatively positioned, the position of the following box is calculated as though B were not offset. The effect of &#39;position:relative&#39; on table-row-group, table-header-group, table-footer-group, table-row, table-column-group, table-column, table-cell, and table-caption elements is undefined.
absolute
The box&#39;s position (and possibly size) is specified with the &#39;top&#39;, &#39;right&#39;, &#39;bottom&#39;, and &#39;left&#39; properties. These properties specify offsets with respect to the box&#39;s containing block. Absolutely positioned boxes are taken out of the normal flow. This means they have no impact on the layout of later siblings. Also, though absolutely positioned boxes have margins, they do not collapse with any other margins.
fixed
The box&#39;s position is calculated according to the &#39;absolute&#39; model, but in addition, the box is fixed with respect to some reference. As with the &#39;absolute&#39; model, the box&#39;s margins do not collapse with any other margins. In the case of handheld, projection, screen, tty, and tv media types, the box is fixed with respect to the viewport and doesn&#39;t move when scrolled. In the case of the print media type, the box is rendered on every page, and is fixed with respect to the page box, even if the page is seen through a viewport (in the case of a print-preview, for example). For other media types, the presentation is undefined. Authors may wish to specify &#39;fixed&#39; in a media-dependent way. For instance, an author may want a box to remain at the top of the viewport on the screen, but not at the top of each printed page. The two specifications may be separated by using an @media rule, as in:
Example(s):
  
@media screen {
  h1#first { position: fixed }
}
@media print {
  h1#first { position: static }
}
UAs must not paginate the content of fixed boxes. Note that UAs may print invisible content in other ways. See &amp;quot;Content outside the page box&amp;quot; in chapter 13.
User agents may treat position as &#39;static&#39; on the root element.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;元素的位置定位影响它的视觉模型，例如：p, h1, div 为块级元素，块级元素在展示的时候是以垂直摆放的，元素之间的垂直距离由垂直间隔决定，即margin。又如：strong、span为inline elements，内联元素。展示为水平摆放，这种元素改变视觉效果只能通过line height、或者水平 border 、padding、margin。&lt;/p&gt;

&lt;h2 id=&#34;relative-position&#34;&gt;relative position&lt;/h2&gt;

&lt;p&gt;相对定位比较简单，就是可以通过属性 top、left、bottom、right来改变它的位置，改变是相对于它的原始位置开始计算的。它于正常的文档流定位类似。跟position的另一个取值static一样，如果不改变它的位置属性值。&lt;/p&gt;

&lt;h2 id=&#34;absolute-position&#34;&gt;absolute position&lt;/h2&gt;

&lt;p&gt;类似于relative position，absolute position是相对于其最近的父节点而摆放。如果没有最近的父节点，就绑定在body元素上。absolute position让其父节点必须是relative position。&lt;/p&gt;

&lt;h2 id=&#34;fixed-position&#34;&gt;fixed position&lt;/h2&gt;

&lt;p&gt;是absolute position的子类，不同的是它的视口是整个window， 利用它就可以固定一个元素在这个窗口视图上，无论怎么滚动这个元素会固定在这个窗口中。&lt;/p&gt;

&lt;h2 id=&#34;floating&#34;&gt;floating&lt;/h2&gt;

&lt;p&gt;floatting也是重要的布局类，经常需要将一个元素靠左或者靠右对齐。靠左或者靠右直到它的外边缘与父节点边缘接壤，或者其他float元素的边缘。float元素并不在正常的文档流中。即只要元素变为float元素了，其所在的body就会将其视为不存在了。在实现那些文字环绕的效果时，都会使用到这个class，因为float元素会脱离正常的文档流，所以在制作这种效果的时候需要用clear配合使用。&lt;/p&gt;

&lt;h1 id=&#34;overflow&#34;&gt;overflow&lt;/h1&gt;

&lt;p&gt;解释：
&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Nginx &#43; Docker Cluster &amp; session sticky</title>
      <link>http://www.heguangnan.com/post/nginx-session/</link>
      <pubDate>Mon, 06 Jul 2015 17:45:07 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/nginx-session/</guid>
      <description>基本配置 本地开发环境和生产环境还是有很大的区分，最近性能测试发现结果很不好，于是想自己去搭建一个类似生产环境的性能测试环境。
由于前期已经有了docker的开发环境，这里只需要增加Nginx 作为反向代理。 在/etc/nginx/conf.d目录下新建文件例如proxyServer.conf，添加如下内容
## Basic reverse proxy server upstream dockerServer { ip_hash; server 10.128.163.121:7080; server 10.128.163.121:17080; } upstream dockerServerSSL { ip_hash; server 10.128.163.121:7443; server 10.128.163.121:17443; } server { listen 80; server_name 10.128.163.121; ##access_log logs/60.access.log main; error_log logs/60.error.log; root html; index index.html index.htm index.php; ## send request back to apache ## location / { proxy_pass http://dockerServer ; #Proxy Settings proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; proxy_max_temp_file_size 0; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; } } server { listen 443; server_name 10.</description>
    </item>
    
    <item>
      <title>deadlock of mysql</title>
      <link>http://www.heguangnan.com/post/deadloc/</link>
      <pubDate>Fri, 26 Jun 2015 15:45:07 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/deadloc/</guid>
      <description>没有想到在看似简单的场景里面也能遇到mysql的deadlock。
[Thu Jun 25 05:18:40.589897 2015] [:error] [pid 737] [client 172.17.42.1:41290] WordPress database error Deadlock found when trying to get lock; try restarting transaction for query UPDATE `wp_usermeta` SET `meta_value` = &#39;a:2:{s:64:\\&amp;quot;1161a6271c528045db428cc8698bbc8e3e26ad4fb9d7436e32cbbe01a00079d0\\&amp;quot;;i:1436419120;s:64:\\&amp;quot;bf2e3582e17c7dfa1e6b02c700f537b8095f2b31ef58e4b448939eb9406e11f7\\&amp;quot;;i:1435382320;}&#39; WHERE `user_id` = 188 AND `meta_key` = &#39;session_tokens&#39; made by require(&#39;wp-blog-header.php&#39;), require_once(&#39;wp-includes/template-loader.php&#39;), do_action(&#39;template_redirect&#39;), call_user_func_array, anw_template_redirect, ANW_Base_Controller-&amp;gt;process, call_user_func, ANW_AccountOnePage_Controller-&amp;gt;authenticate, wp_signon, wp_set_auth_cookie, WP_Session_Tokens-&amp;gt;create, WP_Session_Tokens-&amp;gt;update, WP_User_Meta_Session_Tokens-&amp;gt;update_session, WP_User_Meta_Session_Tokens-&amp;gt;update_sessions, update_user_meta, update_metadata  这是wordpress本身的缺陷导致的，死锁的场景也是不复杂。即session_tokens的更新机制所致。 Session_tokens的更新是随着用户的login和 logout 更新的。Login时会增加session_tokens, 在不同的 浏览器 login会增加新的 tokens，在 logout时会删除这个 tokens。 这个死锁用户有两个 session，场景可能就是不同的浏览器同时做 login或者 logout，或者一个 login另一个 logout。看这个环境上有大量的用户存在，并且每个用户至多有两个 session，也只有跑性能脚本会有这个问题。现实情况比较难复现。</description>
    </item>
    
    <item>
      <title>About</title>
      <link>http://www.heguangnan.com/about/</link>
      <pubDate>Sat, 20 Jun 2015 14:02:37 +0200</pubDate>
      
      <guid>http://www.heguangnan.com/about/</guid>
      <description>没错这是一首歌:
What if the storm ends and I don&amp;rsquo;t see you As you are now ever again? The perfect halo of gold hair and lightning Sets you off against the planet&amp;rsquo;s last dance
Just for a minute the silver-forked sky Lifts you up like a star that I will follow But now it&amp;rsquo;s found us like I have a found you I don&amp;rsquo;t wanna run, just overwhelm me
What if the storm ends?</description>
    </item>
    
    <item>
      <title>Tags</title>
      <link>http://www.heguangnan.com/tags/</link>
      <pubDate>Sat, 20 Jun 2015 14:02:37 +0200</pubDate>
      
      <guid>http://www.heguangnan.com/tags/</guid>
      <description>Lorem ipsum dolor sit amet, consectetur adipisicing elit. Ipsa ullam earum dolorum! Sed, perspiciatis.
Lorem ipsum dolor sit amet, consectetur adipisicing elit.
Lorem ipsum dolor. Lorem ipsum dolor sit amet, consectetur adipisicing elit. Ea dicta corporis ad inventore itaque impedit dolor atque amet exercitationem! Veniam qui voluptas maiores vel laudantium necessitatibus, velit ducimus! Iste hic facere, accusamus fugiat enim facilis.</description>
    </item>
    
    <item>
      <title>Docker Docker</title>
      <link>http://www.heguangnan.com/post/docker-docker/</link>
      <pubDate>Fri, 19 Jun 2015 17:45:07 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/docker-docker/</guid>
      <description>一直想把本地的开发环境切换到docker上，由于公司的CI出来的运行环境是docker的，所以把本地开发环境打造成docker的应该也很简单了。
首先安装虚拟机，使用Vmplayer，下载Ubuntu的安装镜像文件，安装会非常简单。接下来就是docker的安装，docker安装依照官网即可
公司的镜像是基于Ubuntu+wordpress+Apache，MySQL在宿主机上。运行container的时候带上相应的参数，这里主要是端口映射，将docker里面的80端口映射到宿主机上的某一个端口例如7080，最后运行起来类似这个样子：
CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ff1ad6f22e91 eshop_612:latest &amp;quot;/var/eshop/install/ 31 hours ago Up 31 hours 0.0.0.0:7022-&amp;gt;22/tcp, 0.0.0.0:7080-&amp;gt;80/tcp, 0.0.0.0:7443-&amp;gt;443/tcp eshop_instance_7080  开始遇到一个问题就是这个端口的映射问题，起来后外部访问时还是用的宿主机的Apache，后续停掉宿主机的Apache，目的是干掉80监听端口，在docker里面增加proxy。后面就一路畅通了。
修改源码如何更新到docker里面是个麻烦的事情，如果有个外挂文件目录的功能就好了，现在只能是修改后的代码传到docker里面。其实传代码也很简单，相比以前编写C++代码，先把本地代码传到Linux服务器上进行编译，编译完再传到运行的服务器上，已经简单多了。现在做的只是把修改后的代码通过filezilla传到docker里面，然后浏览器访问就ok了。
dokcer的开发环境相对于本地的开发环境速度上有个质的飞跃，由于本地是XAMPP的，然后在windows上。很显然web的开发环境更适宜运行在docker里面了。
当然还有个非常大的优点，你可以运行任意多个container，每个container里面的code版本可以不一样啊，尤其在多版本并行开发的时候，带来的开发体验是本地不能有的。</description>
    </item>
    
    <item>
      <title>libuv 初认识</title>
      <link>http://www.heguangnan.com/post/libuv-start/</link>
      <pubDate>Wed, 03 Jun 2015 19:45:07 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/libuv-start/</guid>
      <description>说明： 本篇文章主要从An Introduction to libuv这本书翻译学习而来。
开始 libuv是NodeJS的底层库，实现了异步、事件驱动的编程模式。主要功能就是实现了事件循环，基于I/O或者其他事件的通知回调。比如广泛使用回调的定时器、非阻塞的网络通信、异步的文件读取、子线程相关的通信等等。
事件循环 libuv的编译就不用多说，参考libuv的github网址。就能轻松搞定。我是在Linux上做的相关实验，版本是： Linux ubuntu 3.16.0-33-generic #44~14.04.1-Ubuntu SMP Fri Mar 13 10:33:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux。
先从运行一个程序开始：
#include &amp;quot;uv.h&amp;quot; #include &amp;lt;stdio.h&amp;gt; #include &amp;lt;stdlib.h&amp;gt; int main() { uv_loop_t *loop = malloc(sizeof(uv_loop_t)); uv_loop_init(loop); printf(&amp;quot;Now quitting.\n&amp;quot;); uv_run(loop, UV_RUN_DEFAULT); uv_loop_close(loop); free(loop); return 0; }  编译要使用gyp，因为源码包里面带有相应的samples，根据samples很容易的写出一个gyp 的build文件：
{ &#39;targets&#39;: [ { &#39;dependencies&#39;: [&#39;../../uv.gyp:libuv&#39;], &#39;target_name&#39;: &#39;helloword&#39;, &#39;type&#39;: &#39;executable&#39;, &#39;sources&#39;: [ &#39;main.c&#39;, ] } ], }  然后执行** gyp &amp;ndash;format=make -Duv_library=static_library &amp;ndash;depth=$PWD build.</description>
    </item>
    
    <item>
      <title>同步、异步、阻塞、非阻塞I/O</title>
      <link>http://www.heguangnan.com/post/aio-block/</link>
      <pubDate>Sun, 24 May 2015 14:45:07 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/aio-block/</guid>
      <description>NodeJS倡导异步编程，高并发，高性能。他自然是异步非阻塞I/O。非阻塞I/O是不是就是异步的，跟异步编程又有什么区别呢？写到这里突然想到了大学里的辅导员，刚入大学的第一次开会，就告诫我们，学数学最重要的就是概念，概念不清就什么都学不好。我深深记住了这句话，受用至今。
先看看阻塞和非阻塞，阻塞，顾名思义，即在读取数据时，阻塞在等待数据，或者监听事件时阻塞，有新的数据或者事件，事件是泛化概念，数据到达也是个事件。可以用事件代替一切吧，统称event。非阻塞即调用接口触发某种event，没有任何event也不会阻塞，而是直接返回。
非阻塞返回后干什么，这就牵扯到同步和异步之分了。阻塞就不用多说了显而易见的同步行为。在非阻塞的基础上再进行区分同步和异步。非阻塞在Linux上一般都会使用性能较好的epoll实现，epoll会轮询这些阻塞上的事件，有事务返回便会调用相应的处理流程。那这个是不是异步的呢，还是要看在哪个角度上说，站在非阻塞的角度上，因同时处理多个事件，增加并发性，多个阻塞event进行了异步处理；在轮询线程上说，因还是在不断的轮询它所关心的事件，某一个事件返回时就要进行相应的处理，在这个角度上讲，这个线程可以同步处理多个异步事件，它是同步的。但是在一个框架上，如果实现了这种同步处理多个异步事件的行为，在基于这个框架上进行编码的时候，要进行事件回调，这也是NodeJS的行为。NodeJS需要异步编程思想，但是NodeJS是单线程的，NodeJS就是要不断回调那些需要异步处理的事件，但是异步编程会让代码变得难以维护和调试，这个链接有较好的讨论。
AIO是纯正的异步I/O且非阻塞的，本来应该想epoll一样被广泛使用，获得大赞的，但目前看来被诟病太多。例如内核实现的AIO只能是直接I/O的方式，不能有效的利用系统缓存。glibc的AIO利用线程池模拟出来的，但是存在一系列的bug和缺陷。也因此NodeJS的作者重新封装了一个异步非阻塞的库： libuv。
由于NodeJS的异步编程思想，会让代码变得维护困难，调试也非常不直观，后面就出现了协程的思想。这篇文章对NodeJS的协程思想进行了介绍。node-fibers尝试去协程花NodeJS的层层回调。这个module值得研究一下。后续会有个单独的文章对其进行详细的介绍。
NodeJS底层事件循环使用了libuv库，跨平台Linux下使用libev实现，windows下使用IOCP实现，后续也要仔细研究下这个库，应用广泛的东西，必定是好东西，值得学习的东西。</description>
    </item>
    
    <item>
      <title>straight_join when and why</title>
      <link>http://www.heguangnan.com/post/straight-join/</link>
      <pubDate>Tue, 19 May 2015 10:45:07 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/straight-join/</guid>
      <description>&lt;h3 id=&#34;问题过程&#34;&gt;问题过程&lt;/h3&gt;

&lt;p&gt;最近优化了一个查询语句，使用到了straight_join这个查询提示，现对其做下总结。
先看下这个查询语句：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT wp_posts.ID
FROM wp_posts
INNER JOIN wp_postmeta ON (wp_posts.ID = wp_postmeta.post_id)
INNER JOIN
  (SELECT
   STRAIGHT_JOIN DISTINCT wp_posts.ID
   FROM wp_posts
   INNER JOIN wp_postmeta meta0 ON meta0.post_id = wp_posts.id
   AND meta0.meta_key = &#39;sysfield_code&#39;
   AND CAST(meta0.meta_value AS CHAR) LIKE &#39;%s%&#39;
   INNER JOIN wp_postmeta meta1 ON meta1.post_id = wp_posts.id
   AND meta1.meta_key = &#39;price_sales_RMB&#39;
   AND CAST(meta1.meta_value AS DECIMAL(10,4)) &amp;gt; &#39;20&#39;
   INNER JOIN wp_postmeta meta2 ON meta2.post_id = wp_posts.id
   AND meta2.meta_key = &#39;price_standard_RMB&#39;
   AND CAST(meta2.meta_value AS DECIMAL(10,4)) &amp;gt; &#39;20&#39;
   INNER JOIN wp_postmeta meta3 ON meta3.post_id = wp_posts.id
   AND meta3.meta_key = &#39;price_sales_USD&#39;
   AND CAST(meta3.meta_value AS DECIMAL(10,4)) &amp;gt; &#39;10&#39;
   INNER JOIN wp_postmeta meta4 ON meta4.post_id = wp_posts.id
   AND meta4.meta_key = &#39;price_standard_USD&#39;
   AND CAST(meta4.meta_value AS DECIMAL(10,4)) &amp;gt; &#39;5&#39;
   INNER JOIN wp_postmeta meta5 ON meta5.post_id = wp_posts.id
   AND meta5.meta_key = &#39;sysfield_brand&#39;
   AND CAST(meta5.meta_value AS CHAR) = &#39;Midori&#39;
   INNER JOIN wp_postmeta meta6 ON meta6.post_id = wp_posts.id
   AND meta6.meta_key = &#39;sysfield_manufacturer&#39;
   AND CAST(meta6.meta_value AS CHAR) = &#39;aaaaaaaaa&#39;
   INNER JOIN wp_postmeta meta7 ON meta7.post_id = wp_posts.id
   AND meta7.meta_key = &#39;udf_100000001&#39;
   AND CAST(meta7.meta_value AS CHAR) = &#39;肉身&#39;
   INNER JOIN wp_postmeta meta8 ON meta8.post_id = wp_posts.id
   AND meta8.meta_key = &#39;udf_100000004&#39;
   AND CAST(meta8.meta_value AS CHAR) = &#39;30&#39;
   WHERE 1=1
     AND (wp_posts.post_type = &#39;product&#39;)
     AND (wp_posts.post_status = &#39;publish&#39;
          OR wp_posts.post_status = &#39;private&#39;)
     AND wp_posts.post_title LIKE &#39;%s%&#39;
     AND (wp_posts.ID IN
            (SELECT object_id
             FROM wp_term_relationships
             WHERE term_taxonomy_id IN
                 (SELECT term_taxonomy_id
                  FROM wp_term_taxonomy
                  WHERE term_id IN (100000001))))
     AND wp_posts.post_date &amp;gt; &#39;2015-06-04 10:40:00&#39;) collection ON collection.ID = wp_posts.ID
INNER JOIN
  (SELECT DISTINCT wp_posts.ID
   FROM wp_posts
   INNER JOIN wp_postmeta meta0 ON meta0.post_id = wp_posts.id
   AND (meta0.meta_key = &#39;price_standard_min_RMB&#39;
        AND CAST(meta0.meta_value AS DECIMAL(10,4)) BETWEEN &#39;0&#39; AND &#39;0&#39;)
   INNER JOIN wp_postmeta meta1 ON meta1.post_id = wp_posts.id
   AND (meta1.meta_key = &#39;sysfield_manufacturer&#39;
        AND CAST(meta1.meta_value AS CHAR) = &#39;aaaaaaaaa&#39;)
   INNER JOIN wp_postmeta meta2 ON meta2.post_id = wp_posts.id
   AND (meta2.meta_key = &#39;sysfield_brand&#39;
        AND CAST(meta2.meta_value AS CHAR) = &#39;Midori&#39;)
   INNER JOIN wp_postmeta meta3 ON meta3.post_id = wp_posts.id
   AND (meta3.meta_key = &#39;sysfield_stamp&#39;
        AND CAST(meta3.meta_value AS CHAR) = &#39;sddd&#39;)
   INNER JOIN wp_postmeta meta4 ON meta4.post_id = wp_posts.id
   AND (meta4.meta_key = &#39;udf_100000001&#39;
        AND CAST(meta4.meta_value AS CHAR) IN (&#39;人肉&#39;,
                                               &#39;肉身&#39;,
                                               &#39;精神&#39;))
   INNER JOIN wp_postmeta meta5 ON meta5.post_id = wp_posts.id
   AND (meta5.meta_key = &#39;udf_100000002&#39;
        AND CAST(meta5.meta_value AS CHAR) IN (&#39;20&#39;,
                                               &#39;30&#39;,
                                               &#39;40&#39;))
   INNER JOIN wp_postmeta meta6 ON meta6.post_id = wp_posts.id
   AND (meta6.meta_key = &#39;udf_100000003&#39;
        AND CAST(meta6.meta_value AS CHAR) IN (&#39;10&#39;,
                                               &#39;20&#39;,
                                               &#39;30&#39;))
   INNER JOIN wp_postmeta meta7 ON meta7.post_id = wp_posts.id
   AND (meta7.meta_key = &#39;udf_100000004&#39;
        AND CAST(meta7.meta_value AS CHAR) IN (&#39;30&#39;,
                                               &#39;40&#39;,
                                               &#39;50&#39;))
   INNER JOIN wp_postmeta meta8 ON meta8.post_id = wp_posts.id
   AND (meta8.meta_key = &#39;variant_200000001&#39;
        AND CAST(meta8.meta_value AS CHAR) IN (&#39;200000001&#39;,
                                               &#39;200000002&#39;,
                                               &#39;200000003&#39;))
   INNER JOIN wp_postmeta meta9 ON meta9.post_id = wp_posts.id
   AND (meta9.meta_key = &#39;variant_200000002&#39;
        AND CAST(meta9.meta_value AS CHAR) = &#39;200000006&#39;)
   WHERE 1=1
     AND (wp_posts.post_type = &#39;product&#39;)) filter ON filter.ID = wp_posts.ID
WHERE 1=1
  AND wp_posts.post_type = &#39;product&#39;
  AND (wp_posts.post_status = &#39;publish&#39;
       OR wp_posts.post_status = &#39;private&#39;)
GROUP BY wp_posts.ID
ORDER BY post_date DESC LIMIT 0,
                              12
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;是不是庞大无比，的确这样的查询语句对MySQL来说过去庞大了，因为这个SQL关联次数过多了。
过多的join导致MySQL的查询优化器变得很慢并且往往优化后的结果很不理想。对于MySQL来说N个表的关联就是N的阶层个优化顺序，即MySQL要检查N的阶层个不同的表的顺序，寻找最优化的查询顺序。

通过设置profiling，然后通过** show profile for query xx**得到结果可以说明这一点：&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>高性能MySQL 读书摘要</title>
      <link>http://www.heguangnan.com/post/mysql-note/</link>
      <pubDate>Tue, 19 May 2015 10:45:07 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/mysql-note/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;因工作需要，要不断的使用MySQL，前段时间还参与了MySQL的性能测试，及profiling。发现MySQL还是非常有意思的，自己也非常感兴趣，于是买了本牛逼的书：《高性能MySQL 第三版》。书是很好，但是第一遍基本没什么感觉，基本上是粗略了解，很多细节还是掌握不好。现在重新学习希望能够有更好的提高。
读书摘要，既然是读书摘要就不会照搬原书，我会侧重点的做笔记，有意思的地方会多写，自己觉得不是很重要的东西会少写或者不写。但是内容的范围不会超出这本书。OK, Let&amp;rsquo;s Start。&lt;/p&gt;

&lt;h3 id=&#34;mysql逻辑结构&#34;&gt;MySQL逻辑结构&lt;/h3&gt;

&lt;p&gt;逻辑架构图如下：
&lt;img src=&#34;http://www.heguangnan.com/img/MySqlCapture.PNG&#34; alt=&#34;Mysql&#34; /&gt;
分为三层结构，需要重点研究的是存储引擎层和查询优化层。存储引擎也主要研究InnoDB。&lt;/p&gt;

&lt;h2 id=&#34;并发控制&#34;&gt;并发控制&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;读写锁： 在并发读写数据库表时使用，也叫共享锁和排他锁，读锁是共享的，是互不阻塞的，写锁是排他的，一个写锁会阻塞其他的读锁和写锁。&lt;/li&gt;
&lt;li&gt;锁粒度： 锁的数据越少，并发程度就越高，但锁的数量就会大增，锁的开销也会增加。这就需要一种平衡，即锁策略的选择。&lt;/li&gt;
&lt;li&gt;锁策略，包含&lt;strong&gt;表锁&lt;/strong&gt;和&lt;strong&gt;行级锁&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;死锁： 多个事务以不同的顺序锁定资源时，就会可能产生死锁。InnoDB能检测到死锁的循环依赖（&lt;strong&gt;how?&lt;/strong&gt;），对死锁的处理方法是回滚最少行级排它锁的事务。&lt;/li&gt;
&lt;li&gt;MVCC： 多版本并发控制，是行级锁的变种，在很多情况下避免的加锁操作。工作在REPEATABLE READ 和 REPEATABLE COMMITTED两个隔离级别下。&lt;/li&gt;
&lt;li&gt;事务日志： 提高事务效率的一种方法，也叫预写式日志。日志操作是磁盘上小块区域内的顺序I/O，不是随机I/O，会快很多。关于顺序和随机I/O，需要后面讨论下。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;如何检测死锁，在复杂系统里面是要重点考虑的，目前没有研究InnoDB的源码，不知道他是怎么判定死锁产生的。但是基于一般理论大致可以想一下它是怎么产生的，即多个线程加锁的顺序不一致，产生了循环依赖，基于此，可以设计一种数据结构，每个线程在试图加锁的时候就将该线程作为该锁的所有者，如果出现加锁失败，就要进行一次检测。每个锁的所有者里面是否有环，有环就说明有循环依赖，即可判定死锁，然后进行死锁解除。解除的策略估计会比较暴力，通过销毁某个死锁线程或者强制锁释放等等。&lt;a href=&#34;http://web.mit.edu/6.033/1997/reports/r03-ben.html&#34;&gt;这篇文章&lt;/a&gt;也有类似的讨论。&lt;/p&gt;

&lt;p&gt;InnoDB中的MVCC实现机制： 在每行记录保存两个隐藏的列，一个是行的创建时间，一个是行的过期时间或者是删除时间。时间使用系统版本号标示，每个事务都会有一个，且递增。在REAPTABLE READ隔离级别下MVCC操作如下：
+ SELECT 满足两个条件： InnoDB只查找版本号早于当前事务版本的数据行。行的删除版本要么没有定义要么大于当前事务的版本号。
+ INSERT InnoDB为没一行保存当前系统版本号作为行版本号。
+ DELETE InnoDB为删除的每一行保存当前的版本号为删除版本号。
+ UPDATE InnoDB为新插入的行，保存当前的版本号为行版本号，同时保存当前系统版本号到原来的行作为删除的行作为行删除标示。与单纯的悲观锁和乐观锁，MVCC读操作简单，性能好，能保证只会读到符合标准的行。&lt;/p&gt;

&lt;p&gt;MVCC工作在REAPTABLE READ 和 READ COMMIT两个隔离级别下。REAPTABLE READ 为可重复读，即同一个事务中多次读取同样的记录的结果是一致的。显然MVCC满足这点。READ COMMIT 提交读，一个事务开始时，只能更新到所有已提交事务的更改。即事务开始到提交前，所做的修改对其他事务都是不可见的。MVCC也天生支持。&lt;/p&gt;

&lt;h2 id=&#34;mysql基准测试&#34;&gt;MySQL基准测试&lt;/h2&gt;

&lt;p&gt;本章主要是说的针对MySQL的基准测试，这里重点看下&lt;strong&gt;sql-bench&lt;/strong&gt;和&lt;strong&gt;sysbench&lt;/strong&gt;。 其中&lt;strong&gt;sql-bench&lt;/strong&gt;只有在源码安装的时候才会有，二进制安装没有,&lt;strong&gt;sysbench&lt;/strong&gt;需要单独安装。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;sql-bench&lt;/strong&gt; 是由perl脚本组成的测试工具。&lt;strong&gt;sysbench&lt;/strong&gt;也可以不只是用来进行数据库的基准测试，比如CPU、I/O等。这些工具的使用咱不赘述，后续如有使用再更新到这里。&lt;/p&gt;

&lt;h2 id=&#34;服务器性能剖析&#34;&gt;服务器性能剖析&lt;/h2&gt;

&lt;p&gt;服务器性能剖析包含两个方面，一是应用程序，而是数据库；对应用程序剖析需要有相应的统计方法。例如PHP则需要统计每个方法的执行时间，执行数据库查询的时间，都可以在应用层获取；数据库上的性能剖析，就是分析并发查询时的性能问题。
针对PHP方面，目前正在开发性能剖析的脚本，保证能在生产环境上work。做完后会更新到这里。
数据库方面目前就使用了MySql的慢查询日志。慢查询日志的产生需要简单的配置：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1.  find /etc -name my.cnf; it should be locate in: sudo vi /etc/mysql/my.cnf;
2.  add lines: under [mysqld]
slow-query-log = 1
slow-query-log-file = /var/log/mysql/localhost-slow.log
long_query_time = 1
log-queries-not-using-indexes
if the directory /var/log/mysql/ does not exist, you need use : mkdir –p /var/log/mysql/ to create it.
3.  restart your daemon: sudo service mysql restart .
I have tested these steps on my Ubuntu machine.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;令&lt;strong&gt;long_query_time = 0&lt;/strong&gt;可以获得所有的查询语句，上述配置对MariaDB也是适用的。&lt;/p&gt;

&lt;p&gt;获得的结果类似如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;35 # User@Host: debian-sys-maint[debian-sys-maint] @ localhost []
 36 # Query_time: 0.000169  Lock_time: 0.000075 Rows_sent: 0  Rows_examined: 1
 37 SET timestamp=1430214485;
 38 select count(*) into @discard from `information_schema`.`PROCESSLIST`;
 39 # User@Host: debian-sys-maint[debian-sys-maint] @ localhost []
 40 # Query_time: 0.000359  Lock_time: 0.000111 Rows_sent: 0  Rows_examined: 2
 41 SET timestamp=1430214485;
 42 select count(*) into @discard from `information_schema`.`ROUTINES`;
 43 # User@Host: debian-sys-maint[debian-sys-maint] @ localhost []
 44 # Query_time: 0.001736  Lock_time: 0.000090 Rows_sent: 0  Rows_examined: 0
 45 SET timestamp=1430214485;
 46 select count(*) into @discard from `information_schema`.`TRIGGERS`;
 47 # User@Host: debian-sys-maint[debian-sys-maint] @ localhost []
 48 # Query_time: 0.001403  Lock_time: 0.000080 Rows_sent: 0  Rows_examined: 4
 49 SET timestamp=1430214485;
 50 select count(*) into @discard from `information_schema`.`VIEWS`;
 51 # Time: 150428 17:49:08
 52 # User@Host: root[root] @ localhost []
 53 # Query_time: 0.144277  Lock_time: 0.000052 Rows_sent: 10061  Rows_examined: 10061
 54 use occ_eshop;
 55 SET timestamp=1430214548;
 56 select * from wp_posts;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后可以针对每一个查询进行分析，并剖析其性能问题。
&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>杂记 </title>
      <link>http://www.heguangnan.com/post/zaji-1/</link>
      <pubDate>Mon, 18 May 2015 20:45:07 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/zaji-1/</guid>
      <description>最近一直有所恍惚，不知道自己的定位是什么，未来要做什么。 极力的从一个公司挣脱到另一个公司，发现其实这种跳槽其实意义不大，发生这种事情还是自己考虑不周，不清楚自己的定位导致。 说到定位，想想自己想做什么样的人，未来要做什么样的事情。。。
自己总是一意孤行的想多做点技术方面的工作，不计损失，可要想到任何地方其实都是跟业务相关的，不做业务怎么赚钱呢？纯粹的技术工作会有吗？应该寥寥无几，自己哪有什么本事能去做那样的工作呢。 事情有因必有果，目前的境遇是我的造成的，是我应该面对的。工作和家庭，要轻松的工作可以更多的兼顾家庭，可是赚钱就不会太多；想要赚多点钱就要找奋斗型的公司，工作时间长，家庭生活要少很多。自己已经从后者的生活状态转变为前者，发现前者的生活更加让人迷茫。
每天都很清闲，生活在外企的工作氛围中，你会觉得自己很是个另类，如此的轻松愉快，不好吗？为啥还要有那么多的想法和迷茫呢。 自己感觉是年轻的一类，而且也想更多的实现自身价值和获取更多的成就感。发现自己还是适合奋斗型的。
热烈的想工作，渴望面对更多的技术问题，解决更多的问题。目前阶段算是给自己的一个放松的机会，希望下一次机会来临，自己能够擦亮眼睛获取自己想要的环境，不然你不会幸福的。</description>
    </item>
    
    <item>
      <title>WooCommerce variant product 表设计</title>
      <link>http://www.heguangnan.com/post/woocommerce-variant-product-%E8%A1%A8%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Wed, 13 May 2015 20:45:07 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/woocommerce-variant-product-%E8%A1%A8%E8%AE%BE%E8%AE%A1/</guid>
      <description>随着功能越来越多，越来越复杂，如果数据库表设计的不好，就会遇到各种各样的问题。 目前已经发现数据表设计的非常不合理，导致出现了大量tricky的PHP代码。由于是在Wordpress平台上搭建的电商平台，免不了要借鉴下WooCommerce的表设计了。 WooCommerce是基于Wordpress的一个插件，也能实现快速开店。下面就来分析下WooCommerce中是如何存储和组织产品数据的。在产品数据中，variant product有事最为复杂的一种。比方一件衬衫，它的variant就包含Color和Size，现就以这个例子来分析下WooCommerce中的实现。对于WooCommerce中怎么添加variant product请参照这个链接。但有个主意点就是添加variant product前在Product下面的Attributes tab页里面添加系统级的variants。 首先添加两个attributes分别为Color和Size，添加完后会在wp_woocommerce_attribute_taxonomies出现以下数据：
   attribute_id attribute_name attribute_label attribute_type attribute_orderby attribute_public     4 color Color text id 0   5 size Size text id 0    
接下来去添加variant product，Color下面添加两个值：Red和Green，Size下面也增加两个值：Small和Large。添加完后会有几个表发生变化。首先，wp_terms会增加相应的variant value：
   term_id name slug term_group     15 Red red 0   16 Green green 0   17 Small small 0   18 Large large 0   19 variable variable 0     wp_term_taxonomy中新增：</description>
    </item>
    
    <item>
      <title>MYSQL的中文排序问题</title>
      <link>http://www.heguangnan.com/post/mysql%E7%9A%84%E4%B8%AD%E6%96%87%E6%8E%92%E5%BA%8F%E9%97%AE%E9%A2%98/</link>
      <pubDate>Tue, 12 May 2015 13:45:07 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/mysql%E7%9A%84%E4%B8%AD%E6%96%87%E6%8E%92%E5%BA%8F%E9%97%AE%E9%A2%98/</guid>
      <description>&lt;p&gt;最近在做一个产品filter的功能，遇到一个问题需要对中文的label进行排序，开始以为在数据库层就应该可以轻松解决。但是发现在英文的时候排序是ok的，但是中文的时候结果就不再让人满意了。
例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;select distinct m.meta_value as value, m.meta_key as prefix from wp_postmeta m where m.meta_key like &#39;UDF::5&#39; order by CONVERT(value USING gb2312) COLLATE gb2312_chinese_ci;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果如下：&lt;/p&gt;

&lt;table id=&#34;table_results&#34; class=&#34;ajax pma_table&#34;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th colspan=&#34;2&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th class=&#34;draggable column_heading pointer marker&#34; data-column=&#34;value&#34;&gt;&lt;span&gt;&lt;a &gt;value&lt;input type=&#34;hidden&#34; value=&#34;&#34;&gt;&lt;/a&gt;&lt;/span&gt;&lt;/th&gt;&lt;th class=&#34;draggable column_heading pointer marker&#34; data-column=&#34;prefix&#34;&gt;&lt;span&gt;&lt;a &gt;prefix&lt;input type=&#34;hidden&#34; value=&#34;&#34;&gt;&lt;/a&gt;&lt;/span&gt;&lt;/th&gt;&lt;td&gt;&lt;span&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr class=&#34;odd&#34;&gt;&lt;td data-decimals=&#34;0&#34; data-type=&#34;blob&#34; class=&#34;right data      nowrap &#34;&gt;&lt;span&gt;二年级&lt;/span&gt;&lt;/td&gt;&lt;td data-decimals=&#34;0&#34; data-type=&#34;string&#34; class=&#34;right data      nowrap &#34;&gt;&lt;span&gt;UDF::5&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&#34;even&#34;&gt;&lt;td data-decimals=&#34;0&#34; data-type=&#34;blob&#34; class=&#34;right data      nowrap &#34;&gt;&lt;span&gt;三年级&lt;/span&gt;&lt;/td&gt;&lt;td data-decimals=&#34;0&#34; data-type=&#34;string&#34; class=&#34;right data      condition nowrap &#34;&gt;&lt;span&gt;UDF::5&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&#34;odd&#34;&gt;&lt;td data-decimals=&#34;0&#34; data-type=&#34;blob&#34; class=&#34;right data      nowrap &#34;&gt;&lt;span&gt;四年级&lt;/span&gt;&lt;/td&gt;&lt;td data-decimals=&#34;0&#34; data-type=&#34;string&#34; class=&#34;right data      condition nowrap &#34;&gt;&lt;span&gt;UDF::5&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&#34;even&#34;&gt;&lt;td data-decimals=&#34;0&#34; data-type=&#34;blob&#34; class=&#34;right data      nowrap &#34;&gt;&lt;span&gt;五年级&lt;/span&gt;&lt;/td&gt;&lt;td data-decimals=&#34;0&#34; data-type=&#34;string&#34; class=&#34;right data      condition nowrap &#34;&gt;&lt;span&gt;UDF::5&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&#34;odd&#34;&gt;&lt;td data-decimals=&#34;0&#34; data-type=&#34;blob&#34; class=&#34;right data      nowrap &#34;&gt;&lt;span&gt;学前&lt;/span&gt;&lt;/td&gt;&lt;td data-decimals=&#34;0&#34; data-type=&#34;string&#34; class=&#34;right data      condition nowrap &#34;&gt;&lt;span&gt;UDF::5&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&#34;even&#34;&gt;&lt;td data-decimals=&#34;0&#34; data-type=&#34;blob&#34; class=&#34;right data      nowrap &#34;&gt;&lt;span&gt;一年级&lt;/span&gt;&lt;/td&gt;&lt;td data-decimals=&#34;0&#34; data-type=&#34;string&#34; class=&#34;right data      condition nowrap &#34;&gt;&lt;span&gt;UDF::5&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&#34;odd&#34;&gt;&lt;td data-decimals=&#34;0&#34; data-type=&#34;blob&#34; class=&#34;right data      nowrap &#34;&gt;&lt;span&gt;婴幼儿&lt;/span&gt;&lt;/td&gt;&lt;td data-decimals=&#34;0&#34; data-type=&#34;string&#34; class=&#34;right data      condition nowrap &#34;&gt;&lt;span&gt;UDF::5&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&#34;even&#34;&gt;&lt;td data-decimals=&#34;0&#34; data-type=&#34;blob&#34; class=&#34;right data      nowrap &#34;&gt;&lt;span&gt;幼儿园&lt;/span&gt;&lt;/td&gt;&lt;td data-decimals=&#34;0&#34; data-type=&#34;string&#34; class=&#34;right data      condition nowrap &#34;&gt;&lt;span&gt;UDF::5&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
  

&lt;p&gt;上面就是按照中文排序的结果，排序的标准就是按照中文的拼音排序，但是排序的结果还是符合正常的逻辑。
进一步可以看下排序的标准是什么：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;select distinct m.meta_value as value, m.meta_key as prefix, CONVERT(meta_value USING gb2312) COLLATE gb2312_chinese_ci as base from wp_postmeta m where m.meta_key like &#39;UDF::5&#39; order by CONVERT(value USING gb2312) COLLATE gb2312_chinese_ci;
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>blog 路程开启。。。</title>
      <link>http://www.heguangnan.com/post/let-s-start/</link>
      <pubDate>Sat, 09 May 2015 20:45:07 +0800</pubDate>
      
      <guid>http://www.heguangnan.com/post/let-s-start/</guid>
      <description>博客有了，就要开始写。 为什么要写博客呢？看了很多人都推荐写一下博客，这也完全不只是博客那么简单。平时工作谁会有时间写博客呢，当然没有Evernote来的方便，记忆下重要的技术点，以供后续研究学习。
因换工作有将近9个月，做的东西也类似于全栈工程师，不管是前端还是后端，都要学习使用。这样可以接触很多东西，但是相当于拉长了战线，如果想要做的深、学的好，还是非常有挑战的。也就是因为这个新的工作让我接触了Web开发，使用了PHP、Javascript、Mysql，这让我这个之前做了多年C++通信方向开发的人打开眼界。很多东西很有趣但也很有挑战。Web开发虽然入门容易，但是做到专家也是离不开10000小时的规律的。所以像我这个刚刚进入这个领域的人，更要持续努力了。这个Blog不例外也是用hexo生成出来的，theme使用的是NexT，自己在此基础上进行了修改，引入了Bootsrap，调整了些UI，符合我的审美观点吧，虽然非常业余。目前Blog基本功能还是有些bug，后续会慢慢修复和优化，也当成自己的一个训练场吧。
就像这个Blog，GitHub提供了便利，可以随时随地的写，只要能上网就能更新到网站上，很方便。由于之前都没怎么写过博客，写博客还是非常有必要的，锻炼文字的组织能力、总结能力，更能促进学习进步。希望现在开始还一切来得及。
名叫“三十重围”，因为自己已经年近30岁，感觉自己需要突出重围，获得自己理想的追求，把平时自己杂乱的东西要学会统一整理，系统规范。
Blog的开始，重新开始。</description>
    </item>
    
  </channel>
</rss>